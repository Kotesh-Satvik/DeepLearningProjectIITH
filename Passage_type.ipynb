{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579718f1-50eb-488f-b0d9-27ba8a8e8038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 12.1\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa4541c-dcf5-4b0e-a996-0fecae619c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 23:11:54.126303: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 23:11:54.167862: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 23:11:54.894372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install evaluate\n",
    "# !pip install rouge\n",
    "# !pip install spacy\n",
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from nltk.translate import meteor\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import evaluate  # Bleu\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from pytorchtools import EarlyStopping\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07526534-3342-4bdb-9d64-8cc85d39ff7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>article</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[It’ll be just like old times this weekend for...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA sets date for full recovery of ozone hole</td>\n",
       "      <td>[2070 is shaping up to be a great year for Mot...</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>[2070]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is what makes employees happy -- and it's...</td>\n",
       "      <td>[Despite common belief, money isn't the key to...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passion is overrated — 7 work habits you need ...</td>\n",
       "      <td>[It’s common wisdom. Near gospel really, and n...</td>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The perfect way to cook rice so that it's perf...</td>\n",
       "      <td>[Boiling rice may seem simple, but there is a ...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>[A long time ago in a galaxy far, far away...W...</td>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>[it hasn’t necessarily taken the wind out of Y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Cop Is Eating At A Chili's When Teen Hands Him...</td>\n",
       "      <td>[The Kansas City, Kansas Police Department are...</td>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>[It read, \"Thanks for keeping us safe.\"]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[Obama looks decades younger already, but what...</td>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[1. Anti-wrinkle creams will erase the fine li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>You need to see this Twitter account that pred...</td>\n",
       "      <td>[What the HELL?!, 1. Unless you’re somewhere w...</td>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td>[@beyoncefan666]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>GOP congressman comes out for gay marriage</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.) came out in support...</td>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.)]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1        NASA sets date for full recovery of ozone hole   \n",
       "2     This is what makes employees happy -- and it's...   \n",
       "3     Passion is overrated — 7 work habits you need ...   \n",
       "4     The perfect way to cook rice so that it's perf...   \n",
       "...                                                 ...   \n",
       "3195  Has Facebook's video explosion completely shak...   \n",
       "3196  Cop Is Eating At A Chili's When Teen Hands Him...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  You need to see this Twitter account that pred...   \n",
       "3199         GOP congressman comes out for gay marriage   \n",
       "\n",
       "                                                context  \\\n",
       "0     [It’ll be just like old times this weekend for...   \n",
       "1     [2070 is shaping up to be a great year for Mot...   \n",
       "2     [Despite common belief, money isn't the key to...   \n",
       "3     [It’s common wisdom. Near gospel really, and n...   \n",
       "4     [Boiling rice may seem simple, but there is a ...   \n",
       "...                                                 ...   \n",
       "3195  [A long time ago in a galaxy far, far away...W...   \n",
       "3196  [The Kansas City, Kansas Police Department are...   \n",
       "3197  [Obama looks decades younger already, but what...   \n",
       "3198  [What the HELL?!, 1. Unless you’re somewhere w...   \n",
       "3199  [Rep. Charlie Dent (R-Pa.) came out in support...   \n",
       "\n",
       "                                                article  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                                spoiler  labels  \n",
       "0                 [how about that morning we go throw?]       1  \n",
       "1                                                [2070]       0  \n",
       "2                            [intellectual stimulation]       0  \n",
       "3     [Purpose connects us to something bigger and i...       2  \n",
       "4                                    [in a rice cooker]       0  \n",
       "...                                                 ...     ...  \n",
       "3195  [it hasn’t necessarily taken the wind out of Y...       1  \n",
       "3196           [It read, \"Thanks for keeping us safe.\"]       1  \n",
       "3197  [1. Anti-wrinkle creams will erase the fine li...       2  \n",
       "3198                                   [@beyoncefan666]       0  \n",
       "3199                        [Rep. Charlie Dent (R-Pa.)]       0  \n",
       "\n",
       "[3200 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset(file_name):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    \n",
    "    df = []\n",
    "    df_multi = []\n",
    "    df_phrase = []\n",
    "    df_passage = []\n",
    "    with open('/DATA1/ai20btech11028/vojes_nlp/Data/' + file_name, encoding='utf-8') as f:\n",
    "        for i in f:\n",
    "            i = json.loads(i)\n",
    "                \n",
    "            tweet = i['postText']\n",
    "            article_title = i['targetTitle']\n",
    "            article = ' '.join(i['targetParagraphs'])\n",
    "            spoilers = i['spoiler']\n",
    "            label = i['tags']\n",
    "            \n",
    "            assert len(tweet) == 1\n",
    "            tweet = tweet[0]\n",
    "            \n",
    "            assert len(label) == 1\n",
    "            label = label[0]\n",
    "            \n",
    "            if label not in ['phrase', 'phrases', 'passage', 'multi']:\n",
    "                print(label)\n",
    "                \n",
    "            assert label in ['phrase', 'phrases', 'passage', 'multi']\n",
    "            \n",
    "            if label == 'phrase' or label == 'phrases':\n",
    "                label = 0\n",
    "            elif label == 'multi':\n",
    "                label = 2\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "            \n",
    "            df += [{'question': tweet , 'context': i['targetParagraphs'], 'article': article_title + article, 'spoiler':spoilers,\n",
    "                    'labels': label}]\n",
    "\n",
    "    return pd.DataFrame(df)\n",
    "            \n",
    "    \n",
    "# # test_dataset = load_dataset('test.jsonl')\n",
    "train_dataset = load_dataset('train.jsonl')\n",
    "validation_dataset = load_dataset('validation.jsonl')\n",
    "# print(train_dataset)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa58031b-65b1-4969-a461-d19ef5750065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"MateuszW/generated_questions\")\n",
    "\n",
    "genQue_train = dataset['train']['generated_questions']\n",
    "genQue_test = dataset['validation']['generated_questions']\n",
    "# print(genQue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5584164a-49fb-4d3e-8cb9-793ce8b885b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>article</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>labels</th>\n",
       "      <th>generated_que</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[It’ll be just like old times this weekend for...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "      <td>1</td>\n",
       "      <td>What did Tom Brady do instead of having dinner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA sets date for full recovery of ozone hole</td>\n",
       "      <td>[2070 is shaping up to be a great year for Mot...</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>[2070]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the date that NASA has set for the ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is what makes employees happy -- and it's...</td>\n",
       "      <td>[Despite common belief, money isn't the key to...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "      <td>0</td>\n",
       "      <td>What makes employees happy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passion is overrated — 7 work habits you need ...</td>\n",
       "      <td>[It’s common wisdom. Near gospel really, and n...</td>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>What are the 7 work habits that are considered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The perfect way to cook rice so that it's perf...</td>\n",
       "      <td>[Boiling rice may seem simple, but there is a ...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the best way to cook rice so that it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>[A long time ago in a galaxy far, far away...W...</td>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>[it hasn’t necessarily taken the wind out of Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Cop Is Eating At A Chili's When Teen Hands Him...</td>\n",
       "      <td>[The Kansas City, Kansas Police Department are...</td>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>[It read, \"Thanks for keeping us safe.\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>What did the teen give the cop?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[Obama looks decades younger already, but what...</td>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[1. Anti-wrinkle creams will erase the fine li...</td>\n",
       "      <td>2</td>\n",
       "      <td>What are the 5 popular myths about visible sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>You need to see this Twitter account that pred...</td>\n",
       "      <td>[What the HELL?!, 1. Unless you’re somewhere w...</td>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td>[@beyoncefan666]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the purpose of the Twitter account men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>GOP congressman comes out for gay marriage</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.) came out in support...</td>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.)]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the name of the GOP congressman who ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1        NASA sets date for full recovery of ozone hole   \n",
       "2     This is what makes employees happy -- and it's...   \n",
       "3     Passion is overrated — 7 work habits you need ...   \n",
       "4     The perfect way to cook rice so that it's perf...   \n",
       "...                                                 ...   \n",
       "3195  Has Facebook's video explosion completely shak...   \n",
       "3196  Cop Is Eating At A Chili's When Teen Hands Him...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  You need to see this Twitter account that pred...   \n",
       "3199         GOP congressman comes out for gay marriage   \n",
       "\n",
       "                                                context  \\\n",
       "0     [It’ll be just like old times this weekend for...   \n",
       "1     [2070 is shaping up to be a great year for Mot...   \n",
       "2     [Despite common belief, money isn't the key to...   \n",
       "3     [It’s common wisdom. Near gospel really, and n...   \n",
       "4     [Boiling rice may seem simple, but there is a ...   \n",
       "...                                                 ...   \n",
       "3195  [A long time ago in a galaxy far, far away...W...   \n",
       "3196  [The Kansas City, Kansas Police Department are...   \n",
       "3197  [Obama looks decades younger already, but what...   \n",
       "3198  [What the HELL?!, 1. Unless you’re somewhere w...   \n",
       "3199  [Rep. Charlie Dent (R-Pa.) came out in support...   \n",
       "\n",
       "                                                article  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                                spoiler  labels  \\\n",
       "0                 [how about that morning we go throw?]       1   \n",
       "1                                                [2070]       0   \n",
       "2                            [intellectual stimulation]       0   \n",
       "3     [Purpose connects us to something bigger and i...       2   \n",
       "4                                    [in a rice cooker]       0   \n",
       "...                                                 ...     ...   \n",
       "3195  [it hasn’t necessarily taken the wind out of Y...       1   \n",
       "3196           [It read, \"Thanks for keeping us safe.\"]       1   \n",
       "3197  [1. Anti-wrinkle creams will erase the fine li...       2   \n",
       "3198                                   [@beyoncefan666]       0   \n",
       "3199                        [Rep. Charlie Dent (R-Pa.)]       0   \n",
       "\n",
       "                                          generated_que  \n",
       "0     What did Tom Brady do instead of having dinner...  \n",
       "1     What is the date that NASA has set for the ful...  \n",
       "2                           What makes employees happy?  \n",
       "3     What are the 7 work habits that are considered...  \n",
       "4     What is the best way to cook rice so that it's...  \n",
       "...                                                 ...  \n",
       "3195  Has Facebook's video explosion completely shak...  \n",
       "3196                    What did the teen give the cop?  \n",
       "3197  What are the 5 popular myths about visible sig...  \n",
       "3198  What is the purpose of the Twitter account men...  \n",
       "3199  What is the name of the GOP congressman who ca...  \n",
       "\n",
       "[3200 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"generated_que\"] = list(genQue_train)\n",
    "validation_dataset[\"generated_que\"] = list(genQue_test)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab52a82-5f1c-44a3-af18-51dba8850663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = T5TokenizerFast.from_pretrained('castorini/monot5-base-msmarco-10k')\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained('castorini/monot5-base-msmarco-10k', return_dict=True).to(DEVICE)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.0001)\n",
    "Q_LEN = 256   # Question Length\n",
    "T_LEN = 256    # Target Length\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = \"cuda:0\"\n",
    "# patience = 10\n",
    "# early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8678a3a2-07f8-4002-8add-53b908ffacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the data\n",
    "\n",
    "# with open('../input/squaddata/squad_train.json') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa17177-765e-42cc-b0f1-70c0557dd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting context, question, and answers from the dataset\n",
    "\n",
    "def prepare_data(train_dataset):\n",
    "    articles = []\n",
    "    \n",
    "    for i in range(len(train_dataset)):\n",
    "      clickbait = train_dataset.iloc[i]\n",
    "      if clickbait['labels'] == 1:\n",
    "        context = clickbait['article']\n",
    "        question = clickbait['generated_que']\n",
    "        answer = ' '.join(clickbait['spoiler'])\n",
    "\n",
    "        inputs = {\"context\": context, \"question\": question, \"answer\": answer}\n",
    "\n",
    "        articles.append(inputs)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05423bee-452f-42ce-ab8b-982884df6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(train_dataset)\n",
    "# Create a Dataframe\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3f2bebb-0ac4-44f0-8f29-346bad5c5f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>What did Tom Brady do instead of having dinner...</td>\n",
       "      <td>how about that morning we go throw?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here's what happens if your Apple AirPods get ...</td>\n",
       "      <td>What is the policy of Apple regarding lost or ...</td>\n",
       "      <td>Apple says that if AirPods are lost or stolen,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Reason Why Gabor Kiraly Wears THOSE Tracki...</td>\n",
       "      <td>What is the reason why Gabor Kiraly wears thos...</td>\n",
       "      <td>\"The more good games I had in them, the more I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You’ll Never Believe What This Family Saw in t...</td>\n",
       "      <td>What did the family see in the sky outside the...</td>\n",
       "      <td>rainbow colours in the sky and a halo spanning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Should I Drink Red Wine?5/5 say yes. Cheers to...</td>\n",
       "      <td>What are the health benefits of drinking red w...</td>\n",
       "      <td>Red wine is clearly the drink of choice if you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>Women Reveal What They Think The Sexiest Part ...</td>\n",
       "      <td>What do women think is the sexiest part of a man?</td>\n",
       "      <td>almost every other part of a man is considered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Here's Another Huge Reason To Eat A Plant-Base...</td>\n",
       "      <td>What is the huge reason to eat a plant-based d...</td>\n",
       "      <td>may cut your risk for colorectal cancer -- the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>If You See A Purple Butterfly Sticker At The H...</td>\n",
       "      <td>What does the purple butterfly sticker mean at...</td>\n",
       "      <td>one of her unborn twins had a condition called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>it hasn’t necessarily taken the wind out of Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>What did the teen give the cop?</td>\n",
       "      <td>It read, \"Thanks for keeping us safe.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Here's what happens if your Apple AirPods get ...   \n",
       "2     The Reason Why Gabor Kiraly Wears THOSE Tracki...   \n",
       "3     You’ll Never Believe What This Family Saw in t...   \n",
       "4     Should I Drink Red Wine?5/5 say yes. Cheers to...   \n",
       "...                                                 ...   \n",
       "1269  Women Reveal What They Think The Sexiest Part ...   \n",
       "1270  Here's Another Huge Reason To Eat A Plant-Base...   \n",
       "1271  If You See A Purple Butterfly Sticker At The H...   \n",
       "1272  Facebook Video Surging, But YouTube Still Offe...   \n",
       "1273  Cop is eating at Chili's when teen hands him f...   \n",
       "\n",
       "                                               question  \\\n",
       "0     What did Tom Brady do instead of having dinner...   \n",
       "1     What is the policy of Apple regarding lost or ...   \n",
       "2     What is the reason why Gabor Kiraly wears thos...   \n",
       "3     What did the family see in the sky outside the...   \n",
       "4     What are the health benefits of drinking red w...   \n",
       "...                                                 ...   \n",
       "1269  What do women think is the sexiest part of a man?   \n",
       "1270  What is the huge reason to eat a plant-based d...   \n",
       "1271  What does the purple butterfly sticker mean at...   \n",
       "1272  Has Facebook's video explosion completely shak...   \n",
       "1273                    What did the teen give the cop?   \n",
       "\n",
       "                                                 answer  \n",
       "0                   how about that morning we go throw?  \n",
       "1     Apple says that if AirPods are lost or stolen,...  \n",
       "2     \"The more good games I had in them, the more I...  \n",
       "3     rainbow colours in the sky and a halo spanning...  \n",
       "4     Red wine is clearly the drink of choice if you...  \n",
       "...                                                 ...  \n",
       "1269  almost every other part of a man is considered...  \n",
       "1270  may cut your risk for colorectal cancer -- the...  \n",
       "1271  one of her unborn twins had a condition called...  \n",
       "1272  it hasn’t necessarily taken the wind out of Yo...  \n",
       "1273             It read, \"Thanks for keeping us safe.\"  \n",
       "\n",
       "[1274 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57345d6a-743a-4317-8894-88e04f377ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answer']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx]\n",
    "        \n",
    "        question_tokenized = self.tokenizer(question, context, max_length=self.q_len, padding=\"max_length\",\n",
    "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        \n",
    "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2ca788-6bb8-4fa1-a106-3294c1e63ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b24eb27d-52e9-4f8b-90ab-6bbc2b4c5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:32<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 -> Train loss: 1.7926707342267036\tValidation loss: 1.144106574356556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:32<00:00,  1.98it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/5 -> Train loss: 1.5634514749981463\tValidation loss: 0.9956340454518795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 -> Train loss: 1.4313409198075533\tValidation loss: 0.8598200467725595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.92it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/5 -> Train loss: 1.329348806408234\tValidation loss: 0.7461007186211646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.91it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 -> Train loss: 1.23939648992382\tValidation loss: 0.6456964026205242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/5 -> Train loss: 1.1627696240320802\tValidation loss: 0.5631057103552545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/5 -> Train loss: 1.0937151229009032\tValidation loss: 0.49510289718663053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/5 -> Train loss: 1.030225093010813\tValidation loss: 0.43992169022385497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/5 -> Train loss: 0.9735188672008613\tValidation loss: 0.3944549755607214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.91it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/5 -> Train loss: 0.9206910871667787\tValidation loss: 0.35728527822648176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [01:00<00:00,  1.06it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/5 -> Train loss: 0.871908909403084\tValidation loss: 0.3263283006301869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/5 -> Train loss: 0.8282022989878897\tValidation loss: 0.2999378592830908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/5 -> Train loss: 0.7875532895290794\tValidation loss: 0.27742442535348416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/5 -> Train loss: 0.7499169982932342\tValidation loss: 0.25800086520030163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.91it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/5 -> Train loss: 0.7155453233766215\tValidation loss: 0.24107740870070604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.92it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/5 -> Train loss: 0.6846931758936989\tValidation loss: 0.22632440825941558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.92it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/5 -> Train loss: 0.6559983334822498\tValidation loss: 0.2131857188015762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.91it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/5 -> Train loss: 0.6286924384589333\tValidation loss: 0.20145608882153787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/5 -> Train loss: 0.6033218963099276\tValidation loss: 0.19094626965862085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|█████████████████████████████████████████████████████████████████| 64/64 [00:33<00:00,  1.90it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 16/16 [00:08<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/5 -> Train loss: 0.5795630504988367\tValidation loss: 0.18147442810186476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "    \n",
    "    #Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "\n",
    "     # early_stopping(val_loss, MODEL)\n",
    "        \n",
    "     #    if early_stopping.early_stop:\n",
    "     #        print(\"Early stopping\")\n",
    "     #        break\n",
    "        \n",
    "    print(f\"{epoch+1}/{5} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f14332f5-eb0b-47d5-8a09-933d6e341b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('qa_tokenizer/tokenizer_config.json',\\n 'qa_tokenizer/special_tokens_map.json',\\n 'qa_tokenizer/spiece.model',\\n'qa_tokenizer/added_tokens.json',\\n'qa_tokenizer/tokenizer.json')\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.save_pretrained(\"qa_model_flant5\")\n",
    "TOKENIZER.save_pretrained(\"qa_tokenizer_flant5\")\n",
    "\n",
    "# Saved files\n",
    "\"\"\"('qa_tokenizer/tokenizer_config.json',\n",
    " 'qa_tokenizer/special_tokens_map.json',\n",
    " 'qa_tokenizer/spiece.model',\n",
    "'qa_tokenizer/added_tokens.json',\n",
    "'qa_tokenizer/tokenizer.json')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb6b5c2f-c648-4437-ae0f-329b0045073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(val_loader):\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        # outputs = MODEL(\n",
    "        #                   input_ids=input_ids,\n",
    "        #                   attention_mask=attention_mask,\n",
    "        #                   labels=labels,\n",
    "        #                   decoder_attention_mask=decoder_attention_mask\n",
    "        #                 )\n",
    "            \n",
    "        # # input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "        # # attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    \n",
    "        outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "      \n",
    "        predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "902fd7ef-29de-4470-af3d-d4a2106b6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, ref_answer=None):\n",
    "    inputs = TOKENIZER(question, context, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    \n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:\n",
    "        # Load the Bleu metric\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        bleu_score = bleu.compute(predictions=[predicted_answer], \n",
    "                            references=[ref_answer])\n",
    "        bert = evaluate.load(\"bertscore\")\n",
    "\n",
    "        bert_score = bert.compute(predictions=[predicted_answer], references=[ref_answer], lang='en')\n",
    "        ref_token = nltk.word_tokenize(predicted_answer)\n",
    "        pre_token = nltk.word_tokenize(ref_answer)\n",
    "        # print(ref_token)\n",
    "        # print(pre_token)\n",
    "        meteor_score = meteor([ref_token], pre_token)\n",
    "        # print(\"Context: \\n\", context)\n",
    "        # print(\"\\n\")\n",
    "        print(\"Question: \", question)\n",
    "        return {\n",
    "            \"Reference Answer: \": ref_answer, \n",
    "            \"Predicted Answer: \": predicted_answer, \n",
    "            \"BLEU Score: \": bleu_score,\n",
    "            \"Bert Score: \": bert_score,\n",
    "            \"Meteor Score: \": meteor_score\n",
    "        }\n",
    "    else:\n",
    "        return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f40d2bce-13c0-4cde-a476-e51d4f1f06c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>article</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>labels</th>\n",
       "      <th>generated_que</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Five Nights at Freddy’s Sequel Delayed for Wei...</td>\n",
       "      <td>[Five Nights at Freddy’s creator Scott Cawthon...</td>\n",
       "      <td>Five Nights at Freddy’s Sequel Delayed for Wei...</td>\n",
       "      <td>[some of the plot elements are so disturbing t...</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the reason for the delay of the sequel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Arizona Sheriff Joe Arpaio’s fate could ha...</td>\n",
       "      <td>[© REUTERS/Laura Segall Maricopa County Sherif...</td>\n",
       "      <td>Why Arizona Sheriff Joe Arpaio’s fate could ha...</td>\n",
       "      <td>[\"intentionally\", could transform a court case...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the word that could determine the fate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here’s how much you should be tipping your hai...</td>\n",
       "      <td>[Here’s how much you should be tipping your ha...</td>\n",
       "      <td>Here’s how much you should be tipping your hai...</td>\n",
       "      <td>[20%]</td>\n",
       "      <td>0</td>\n",
       "      <td>How much should you be tipping your hairdresser?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Harry Potter\" alums reunite for new movie</td>\n",
       "      <td>[The mythology of punk music's evolution can b...</td>\n",
       "      <td>Alan Rickman &amp; Rupert Grint On 'CBGB,' Reuniti...</td>\n",
       "      <td>[Alan Rickman &amp; Rupert Grint, CBGB]</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the name of the new movie in which \"Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man swallowed a microSD card and you won't b...</td>\n",
       "      <td>[PetaPixel is one of my favorite blogs. The wr...</td>\n",
       "      <td>Man swallowed a microSD card and you won't bel...</td>\n",
       "      <td>[a man who swallowed a 64GB microSD card and t...</td>\n",
       "      <td>1</td>\n",
       "      <td>What happened next?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>This is what happens when you leave a hotel cl...</td>\n",
       "      <td>[Instead of encountering a mound of dirty towe...</td>\n",
       "      <td>This Is What Happens When You Leave A Hotel Cl...</td>\n",
       "      <td>[The video below shows the stunned cleaner ini...</td>\n",
       "      <td>1</td>\n",
       "      <td>What happens when you leave a hotel cleaner a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>This Texas GOP elector announces that he won't...</td>\n",
       "      <td>[A Republican elector in Texas says he will no...</td>\n",
       "      <td>Texas GOP elector announces he won't vote for ...</td>\n",
       "      <td>[Christopher Suprun]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the name of the Texas GOP elector who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>This beauty queen cured her acne with one diet...</td>\n",
       "      <td>[Her inspirational journey is encouraging othe...</td>\n",
       "      <td>UK beauty queen cured her severe acne with one...</td>\n",
       "      <td>[Rachel Crawley, High fat vegan plant based di...</td>\n",
       "      <td>2</td>\n",
       "      <td>What diet change cured the beauty queen's acne?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>WikiLeaks' Julian Assange Reported Dead</td>\n",
       "      <td>[On 16 October 2016, WikiLeaks posted a series...</td>\n",
       "      <td>WikiLeaks’ Julian Assange Isn’t Dead, Just Off...</td>\n",
       "      <td>[Julian Assange’s internet link has been inten...</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the meaning of the sentence?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Original \"Law &amp;amp; Order: SVU\" cast member le...</td>\n",
       "      <td>[Richard Belzer is leaving \"Law &amp; Order: SVU.\"...</td>\n",
       "      <td>Richard Belzer Leaving 'Law &amp; Order: SVU': Mun...</td>\n",
       "      <td>[Richard Belzer]</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the name of the original \"Law &amp; Order:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Five Nights at Freddy’s Sequel Delayed for Wei...   \n",
       "1    Why Arizona Sheriff Joe Arpaio’s fate could ha...   \n",
       "2    Here’s how much you should be tipping your hai...   \n",
       "3           \"Harry Potter\" alums reunite for new movie   \n",
       "4    A man swallowed a microSD card and you won't b...   \n",
       "..                                                 ...   \n",
       "795  This is what happens when you leave a hotel cl...   \n",
       "796  This Texas GOP elector announces that he won't...   \n",
       "797  This beauty queen cured her acne with one diet...   \n",
       "798            WikiLeaks' Julian Assange Reported Dead   \n",
       "799  Original \"Law &amp; Order: SVU\" cast member le...   \n",
       "\n",
       "                                               context  \\\n",
       "0    [Five Nights at Freddy’s creator Scott Cawthon...   \n",
       "1    [© REUTERS/Laura Segall Maricopa County Sherif...   \n",
       "2    [Here’s how much you should be tipping your ha...   \n",
       "3    [The mythology of punk music's evolution can b...   \n",
       "4    [PetaPixel is one of my favorite blogs. The wr...   \n",
       "..                                                 ...   \n",
       "795  [Instead of encountering a mound of dirty towe...   \n",
       "796  [A Republican elector in Texas says he will no...   \n",
       "797  [Her inspirational journey is encouraging othe...   \n",
       "798  [On 16 October 2016, WikiLeaks posted a series...   \n",
       "799  [Richard Belzer is leaving \"Law & Order: SVU.\"...   \n",
       "\n",
       "                                               article  \\\n",
       "0    Five Nights at Freddy’s Sequel Delayed for Wei...   \n",
       "1    Why Arizona Sheriff Joe Arpaio’s fate could ha...   \n",
       "2    Here’s how much you should be tipping your hai...   \n",
       "3    Alan Rickman & Rupert Grint On 'CBGB,' Reuniti...   \n",
       "4    Man swallowed a microSD card and you won't bel...   \n",
       "..                                                 ...   \n",
       "795  This Is What Happens When You Leave A Hotel Cl...   \n",
       "796  Texas GOP elector announces he won't vote for ...   \n",
       "797  UK beauty queen cured her severe acne with one...   \n",
       "798  WikiLeaks’ Julian Assange Isn’t Dead, Just Off...   \n",
       "799  Richard Belzer Leaving 'Law & Order: SVU': Mun...   \n",
       "\n",
       "                                               spoiler  labels  \\\n",
       "0    [some of the plot elements are so disturbing t...       1   \n",
       "1    [\"intentionally\", could transform a court case...       2   \n",
       "2                                                [20%]       0   \n",
       "3                  [Alan Rickman & Rupert Grint, CBGB]       2   \n",
       "4    [a man who swallowed a 64GB microSD card and t...       1   \n",
       "..                                                 ...     ...   \n",
       "795  [The video below shows the stunned cleaner ini...       1   \n",
       "796                               [Christopher Suprun]       0   \n",
       "797  [Rachel Crawley, High fat vegan plant based di...       2   \n",
       "798  [Julian Assange’s internet link has been inten...       1   \n",
       "799                                   [Richard Belzer]       0   \n",
       "\n",
       "                                         generated_que  \n",
       "0    What is the reason for the delay of the sequel...  \n",
       "1    What is the word that could determine the fate...  \n",
       "2     How much should you be tipping your hairdresser?  \n",
       "3    What is the name of the new movie in which \"Ha...  \n",
       "4                                  What happened next?  \n",
       "..                                                 ...  \n",
       "795  What happens when you leave a hotel cleaner a ...  \n",
       "796  What is the name of the Texas GOP elector who ...  \n",
       "797    What diet change cured the beauty queen's acne?  \n",
       "798               What is the meaning of the sentence?  \n",
       "799  What is the name of the original \"Law & Order:...  \n",
       "\n",
       "[800 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71989ea3-8c6b-4f44-a6c1-e0d669700419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the reason for the delay of the sequel to Five Nights at Freddy's?\n",
      "{'Reference Answer: ': 'some of the plot elements are so disturbing that they are making him feel sick', 'Predicted Answer: ': 'too dark', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8500030040740967], 'recall': [0.8265589475631714], 'f1': [0.8381170630455017], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happened next?\n",
      "{'Reference Answer: ': 'a man who swallowed a 64GB microSD card and then pooped it into a strainer', 'Predicted Answer: ': \"he couldn't puke it back up, and therefore had to poop it\", 'BLEU Score: ': {'google_bleu': 0.037037037037037035}, 'Bert Score: ': {'precision': [0.8670387268066406], 'recall': [0.845383882522583], 'f1': [0.8560743927955627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.18124507486209612}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the stunning \"Harry Potter\" revelation about Professor McGonagall?\n",
      "{'Reference Answer: ': 'McGonagall was appointed as Dumbledore’s assistant in 1956, not as his replacement.', 'Predicted Answer: ': '\"Professor McGonagall was originally hired by Dumbledore to teach Defense', 'BLEU Score: ': {'google_bleu': 0.06}, 'Bert Score: ': {'precision': [0.8731586933135986], 'recall': [0.8720711469650269], 'f1': [0.8726145625114441], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.2222222222222222}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the answer that J.J. Abrams has given about the post-credits scene in the new 'Star Wars'?\n",
      "{'Reference Answer: ': 'All the scenes are actually in the movie', 'Predicted Answer: ': 'he quickly dismissed the idea, saying: \"No, there’s not. All the', 'BLEU Score: ': {'google_bleu': 0.06896551724137931}, 'Bert Score: ': {'precision': [0.8335531949996948], 'recall': [0.8566540479660034], 'f1': [0.8449457883834839], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.08823529411764705}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What did Kristin Cavallari say about \"The Hills\"?\n",
      "{'Reference Answer: ': '\"I had fake relationships, fake fights. I don\\'t care anymore, I can tell you.', 'Predicted Answer: ': \"'Blah blah blah, I can't believe you said\", 'BLEU Score: ': {'google_bleu': 0.05714285714285714}, 'Bert Score: ': {'precision': [0.8228554725646973], 'recall': [0.8633255958557129], 'f1': [0.8426048755645752], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.2869318181818182}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the cause of death in the sentence?\n",
      "{'Reference Answer: ': \"he'd eaten a peanut butter sandwich and wasn't aware of her peanut allergy\", 'Predicted Answer: ': 'Myriam Ducre-Lemay, 20, died in 2012 after kissing her boyfriend', 'BLEU Score: ': {'google_bleu': 0.021739130434782608}, 'Bert Score: ': {'precision': [0.7836421728134155], 'recall': [0.8445446491241455], 'f1': [0.8129544258117676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.04065040650406504}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the most that the angry ex-boyfriend did?\n",
      "{'Reference Answer: ': 'kicked her and got into a fight with her current boyfriend', 'Predicted Answer: ': 'he took a fighting stance in front of her boyfriend', 'BLEU Score: ': {'google_bleu': 0.07894736842105263}, 'Bert Score: ': {'precision': [0.9035932421684265], 'recall': [0.8981109857559204], 'f1': [0.9008437991142273], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.31250000000000006}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the shocking move made by the local cops against the boy selling teddy bear to buy food?\n",
      "{'Reference Answer: ': 'Dunham picked the boy up and took him to a Subway to get something to eat. He then took him to the Franklin Police Department.', 'Predicted Answer: ': 'police discovered he was trying to sell his teddy bear for food because he', 'BLEU Score: ': {'google_bleu': 0.00980392156862745}, 'Bert Score: ': {'precision': [0.8467742204666138], 'recall': [0.8621750473976135], 'f1': [0.8544052243232727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.09803921568627452}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the secret that parents discovered in their adoptive daughter's family tree?\n",
      "{'Reference Answer: ': 'Not only does Aubrey have cerebral palsy, but she was neglected and abused by her biological mother.', 'Predicted Answer: ': 'Aubrey has cerebral palsy, but she was neglected and abused by her biological', 'BLEU Score: ': {'google_bleu': 0.6142857142857143}, 'Bert Score: ': {'precision': [0.9466792345046997], 'recall': [0.9301621913909912], 'f1': [0.9383480548858643], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8949194042032237}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is melatonin?\n",
      "{'Reference Answer: ': \"The bottom line: Unfortunately, there's not enough solid research out there on whether melatonin supplements are truly an effective and safe way to get to sleep.\", 'Predicted Answer: ': \"melatonin is a hormone released by the brain that helps regulate the body'\", 'BLEU Score: ': {'google_bleu': 0.00909090909090909}, 'Bert Score: ': {'precision': [0.8576525449752808], 'recall': [0.8424500226974487], 'f1': [0.8499833345413208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06410256410256411}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What makes the author think that there will probably never be a \"Dawson's Creek\" reunion?\n",
      "{'Reference Answer: ': \"Kevin Williamson said he didn't want to write it\", 'Predicted Answer: ': 'The Capeside gang will likely never get back together according to \"Dawson\\'', 'BLEU Score: ': {'google_bleu': 0.021739130434782608}, 'Bert Score: ': {'precision': [0.8416296243667603], 'recall': [0.8627638816833496], 'f1': [0.8520656824111938], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.036764705882352935}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the bombshell about the babies that the doctors drop?\n",
      "{'Reference Answer: ': 'Sophie and Riley were considered \"micro-preemies\" and suffered a slew of health issues, like chronic lung disease and holes in their hearts.', 'Predicted Answer: ': 'Sophie and Riley were considered \"micro-preemies.\" But an early ultrasound revealed it', 'BLEU Score: ': {'google_bleu': 0.24489795918367346}, 'Bert Score: ': {'precision': [0.9331269264221191], 'recall': [0.8957763910293579], 'f1': [0.9140702486038208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5110804386166705}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the conflict mentioned in the sentence?\n",
      "{'Reference Answer: ': 'Buss and Jackson announced that they were mutually ending their four-year engagement', 'Predicted Answer: ': \"Phil Jackson wasn't in the mood to stop and catch up. His New York Knick\", 'BLEU Score: ': {'google_bleu': 0.034482758620689655}, 'Bert Score: ': {'precision': [0.843612790107727], 'recall': [0.8322153091430664], 'f1': [0.8378753066062927], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.09090909090909091}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happened next after the tourist ignored the \"Please Don't Touch\" sign in the museum?\n",
      "{'Reference Answer: ': 'In the video, an abstract, wooden sculpture clock appeared not to be working, so a male tourist decided to take matters into his own hands, pulling on weights and levers for more than 30 seconds before the clock came flying off the wall and into pieces on the floor.', 'Predicted Answer: ': 'In the video, an abstract, wooden sculpture clock appeared not to be working, so a', 'BLEU Score: ': {'google_bleu': 0.3142857142857143}, 'Bert Score: ': {'precision': [0.9679954051971436], 'recall': [0.8841516971588135], 'f1': [0.9241758584976196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6763688843164152}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the name of the person mentioned in the sentence?\n",
      "{'Reference Answer: ': 'Brooks would eventually return to a role at News Corp, few expected her to land at Storyful', 'Predicted Answer: ': 'Rebekah Brooks is set to return to News Corp in a role focusing', 'BLEU Score: ': {'google_bleu': 0.16666666666666666}, 'Bert Score: ': {'precision': [0.8599981069564819], 'recall': [0.8793440461158752], 'f1': [0.8695634603500366], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.46759259259259267}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the \"this\" in the sentence referring to?\n",
      "{'Reference Answer: ': 'In February, when Rep. David Jolly introduced his quixotic plan to ban members of Congress from soliciting campaign contributions, the Florida Republican had only six co-sponsors.', 'Predicted Answer: ': 'There is no evidence that lawmakers spending 30 or more hours a week dialing for dollars.', 'BLEU Score: ': {'google_bleu': 0.008771929824561403}, 'Bert Score: ': {'precision': [0.8545829653739929], 'recall': [0.8464741706848145], 'f1': [0.8505092263221741], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.027472527472527472}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happens just seconds later?\n",
      "{'Reference Answer: ': 'At this point, a large dog -- presumably Stella -- bounds into view, runs to one end of the fence and jumps right over it, almost without effort.', 'Predicted Answer: ': '\"Before I made the fence, I had Stella jump a baby gate inside', 'BLEU Score: ': {'google_bleu': 0.04918032786885246}, 'Bert Score: ': {'precision': [0.8794628381729126], 'recall': [0.8440106511116028], 'f1': [0.8613721132278442], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.28718074055969695}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the main reason for the author's poor performance in sports during high school?\n",
      "{'Reference Answer: ': 'Some people are just better at sports than others', 'Predicted Answer: ': \"bad at catching the ball, slow, and not very aggressive. Yet I'd spend\", 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.847761332988739], 'recall': [0.8388363122940063], 'f1': [0.843275249004364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0308641975308642}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the time for getting up close and personal with a rocket launch?\n",
      "{'Reference Answer: ': 'On Tuesday morning, NASA will broadcast its first-ever rocket launch livestream in 360-degree video', 'Predicted Answer: ': 'On Tuesday morning, NASA will broadcast its first-ever rocket launch livestream in 360-degree', 'BLEU Score: ': {'google_bleu': 0.9354838709677419}, 'Bert Score: ': {'precision': [0.9959357976913452], 'recall': [0.9891334772109985], 'f1': [0.9925230145454407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9927268779852366}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the meaning of the sentence?\n",
      "{'Reference Answer: ': 'I don’t think we should be starting to panic', 'Predicted Answer: ': '\"[CANCER] is a disease that occurs when there is no immune system to', 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8129891753196716], 'recall': [0.8318923711776733], 'f1': [0.8223321437835693], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.03225806451612903}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happened to the speaker's honeymoon?\n",
      "{'Reference Answer: ': 'Rudner and her husband rented ATVs. After hitting a speed bump and falling off of the vehicle, her husband shattered his shoulder and Rudner rotated her hip', 'Predicted Answer: ': 'After hitting a speed bump and falling off of the vehicle, her husband shattered', 'BLEU Score: ': {'google_bleu': 0.4909090909090909}, 'Bert Score: ': {'precision': [0.9387145638465881], 'recall': [0.884903073310852], 'f1': [0.9110148549079895], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8976964769647697}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the bedroom blues?\n",
      "{'Reference Answer: ': 'The sadness some men feel at this point may be due to the contrast between the joy of arousal and feeling like a superhero and the sensation of the feel-good hormones wearing off.', 'Predicted Answer: ': \"Men and women experience 'post-coital dysphoria' (PCD)\", 'BLEU Score: ': {'google_bleu': 0.007692307692307693}, 'Bert Score: ': {'precision': [0.8598686456680298], 'recall': [0.8480112552642822], 'f1': [0.853898823261261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.08064516129032258}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the main point being made in this sentence?\n",
      "{'Reference Answer: ': 'But psychedelics may not be as dangerous and addictive as our society thinks.', 'Predicted Answer: ': 'Many of the negative perceptions we have of psychedelics can be traced back', 'BLEU Score: ': {'google_bleu': 0.04}, 'Bert Score: ': {'precision': [0.8779482841491699], 'recall': [0.8828686475753784], 'f1': [0.8804015517234802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.07633587786259544}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What did the guy do wrong?\n",
      "{'Reference Answer: ': 'If you find yourself so moved to store ice cream in your back pocket in Alabama, you’ll pay the price, and we don’t just mean a cold rear end.', 'Predicted Answer: ': 'Some people think they’re crazy and don’t return a video or audio file', 'BLEU Score: ': {'google_bleu': 0.02459016393442623}, 'Bert Score: ': {'precision': [0.8587138652801514], 'recall': [0.8323050737380981], 'f1': [0.8453032374382019], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.3028830579850988}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the main topic of the sentence?\n",
      "{'Reference Answer: ': '\"Although astrologers seek to explain the natural world, they don\\'t usually attempt to critically evaluate whether those explanations are valid — and this is a key part of science.\"', 'Predicted Answer: ': 'A hospital in Argentina is reportedly using astrology to help treat some mental health conditions,', 'BLEU Score: ': {'google_bleu': 0.023809523809523808}, 'Bert Score: ': {'precision': [0.8527121543884277], 'recall': [0.8436373472213745], 'f1': [0.8481504917144775], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1404494382022472}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the name of the latest Hollywood baby?\n",
      "{'Reference Answer: ': 'Rachel Zoe Gives Birth To Her Second Baby Boy!', 'Predicted Answer: ': \"7 lbs 12 oz, beautiful, healthy and we couldn't be happier\", 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.7771357297897339], 'recall': [0.8057403564453125], 'f1': [0.7911795973777771], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Are left-handed people really more creative than right-handed people?\n",
      "{'Reference Answer: ': 'The answer to that is a definitive ... maybe.', 'Predicted Answer: ': 'Scientists have been chipping away at the peculiarities of left-handedness, which occurs', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8300566077232361], 'recall': [0.7924078702926636], 'f1': [0.8107954859733582], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.03937007874015748}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the reason behind the sudden absence of certain letters in big brand names?\n",
      "{'Reference Answer: ': \"it's all part of a massive effort to encourage people around the globe to donate blood\", 'Predicted Answer: ': \"three key letters from their names: A's, B's and O's\", 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.809748649597168], 'recall': [0.8341110944747925], 'f1': [0.8217493295669556], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06578947368421052}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the answer to the question posed in the sentence?\n",
      "{'Reference Answer: ': 'Republican voters would enthusiastically welcome a black candidate, a Donell Trump — so long as he, too, championed nationalist, politically incorrect, anti-immigrant populism.', 'Predicted Answer: ': 'If Trump were black, would the GOP base accept him?', 'BLEU Score: ': {'google_bleu': 0.03636363636363636}, 'Bert Score: ': {'precision': [0.8967515230178833], 'recall': [0.8589876890182495], 'f1': [0.8774635195732117], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.14598540145985403}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the claim made in the sentence?\n",
      "{'Reference Answer: ': 'you’d still have a hard time arguing they were even the worst band on this stage', 'Predicted Answer: ': \"Shit, it's hard to breathe, might set fire to your pubic hair/\", 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8164995908737183], 'recall': [0.8310334086418152], 'f1': [0.8237024545669556], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06535947712418301}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What was the strategy that Obama's female staffers came up with to ensure their voices were heard?\n",
      "{'Reference Answer: ': 'Female staffers adopted a meeting strategy they called \"amplification\": When a woman made a key point, other women would repeat it, giving credit to its author.', 'Predicted Answer: ': 'most of Obama’s senior staffers — such as former chief of staff Rahm E', 'BLEU Score: ': {'google_bleu': 0.00819672131147541}, 'Bert Score: ': {'precision': [0.8090672492980957], 'recall': [0.8113270401954651], 'f1': [0.8101956248283386], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.056818181818181816}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the ways in which Beats Electronics tricks consumers into thinking that its products are premium?\n",
      "{'Reference Answer: ': 'In these headphones, 30% of the weight comes from four tiny metal parts that are there for the sole purpose of adding weight', 'Predicted Answer: ': 'make you think that the company’s plastic headphones are durable products worth the premium price', 'BLEU Score: ': {'google_bleu': 0.05319148936170213}, 'Bert Score: ': {'precision': [0.8667736053466797], 'recall': [0.8498062491416931], 'f1': [0.858206033706665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.14044943820224717}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the theory about why Donald Trump keeps winning?\n",
      "{'Reference Answer: ': 'Solomon’s recent research shows that people who are thinking about death are more likely to say they support him', 'Predicted Answer: ': 'his viewers’ omnipresent fear of death closer to their conscious minds', 'BLEU Score: ': {'google_bleu': 0.02857142857142857}, 'Bert Score: ': {'precision': [0.8591051697731018], 'recall': [0.855474591255188], 'f1': [0.8572859764099121], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.11627906976744187}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the disturbing reason?\n",
      "{'Reference Answer: ': 'They are soaked in a bath of chlorine', 'Predicted Answer: ': 'machine peels, cut them and reshapes them into little mini carrots', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8115930557250977], 'recall': [0.8490657210350037], 'f1': [0.8299065828323364], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the reason that President Obama won't end his vacation?\n",
      "{'Reference Answer: ': 'Because he believes he can monitor the situation as well — or better — from where he is', 'Predicted Answer: ': 'The president has said he will not be visiting Louisiana for the next three months', 'BLEU Score: ': {'google_bleu': 0.030303030303030304}, 'Bert Score: ': {'precision': [0.8485886454582214], 'recall': [0.8412840366363525], 'f1': [0.8449205160140991], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.09803921568627452}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the last utopia?\n",
      "{'Reference Answer: ': 'Mr Thiel, who previously said New Zealand was a \"utopia\" and has invested heavily there, is just one of several US migrants who have realised what the country has to offer.', 'Predicted Answer: ': 'New Zealand is becoming a \"utopia\" for Americans looking to leave', 'BLEU Score: ': {'google_bleu': 0.10869565217391304}, 'Bert Score: ': {'precision': [0.9112522602081299], 'recall': [0.8733741044998169], 'f1': [0.8919112086296082], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.4901960784313727}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the flaw in this argument?\n",
      "{'Reference Answer: ': 'key objectives of MILO’s tour was the promotion of free speech on typically censorious American college campuses', 'Predicted Answer: ': 'He went on to claim that protesters are generally not students, but organized by \"anti-', 'BLEU Score: ': {'google_bleu': 0.016129032258064516}, 'Bert Score: ': {'precision': [0.8351430892944336], 'recall': [0.855712354183197], 'f1': [0.8453026413917542], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.02906976744186046}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What does Donald Trump reject when he undermines the election results?\n",
      "{'Reference Answer: ': 'he would keep the nation \"in suspense\" about whether he will accept the results', 'Predicted Answer: ': '\"One of the prides of this country is the peaceful transition of power and that no matter', 'BLEU Score: ': {'google_bleu': 0.045454545454545456}, 'Bert Score: ': {'precision': [0.8291683197021484], 'recall': [0.8497859239578247], 'f1': [0.8393505811691284], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.08426966292134831}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the 1-Minute Trick mentioned in the sentence?\n",
      "{'Reference Answer: ': 'All you need to do is applying pressure on your sinuses between your eyes and nose and on the back of your head for 60 seconds.', 'Predicted Answer: ': 'applying pressure on your sinuses between your eyes and nose and on the back of your head', 'BLEU Score: ': {'google_bleu': 0.6078431372549019}, 'Bert Score: ': {'precision': [0.958387553691864], 'recall': [0.9177707433700562], 'f1': [0.9376395344734192], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9443483275663208}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are Chris Brown's plans for 2014?\n",
      "{'Reference Answer: ': 'his sixth studio album, \"X,\" will hit stores on May 5', 'Predicted Answer: ': '\"X,\" will hit stores on May 5.', 'BLEU Score: ': {'google_bleu': 0.6296296296296297}, 'Bert Score: ': {'precision': [0.942253589630127], 'recall': [0.8993170261383057], 'f1': [0.9202847480773926], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8767543859649122}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the trouble in paradise that Rose Leslie doesn't want to work with Game Of Thrones beau Kit Harington\n",
      "{'Reference Answer: ': 'wants to achieve her own success', 'Predicted Answer: ': 'wants to achieve her own success away from the gossip-mongers who feed off her high', 'BLEU Score: ': {'google_bleu': 0.3333333333333333}, 'Bert Score: ': {'precision': [0.8862861394882202], 'recall': [0.9771597981452942], 'f1': [0.9295071959495544], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.39893617021276595}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What got better?\n",
      "{'Reference Answer: ': 'On September 10, flash sale site Joss & Main will be selling actual props from the sets', 'Predicted Answer: ': 'On September 10, flash sale site Joss & Main will be selling actual props from', 'BLEU Score: ': {'google_bleu': 0.8787878787878788}, 'Bert Score: ': {'precision': [0.982870876789093], 'recall': [0.9754703044891357], 'f1': [0.9791566133499146], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9875337577160495}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the meaning of the sentence?\n",
      "{'Reference Answer: ': 'Naturally Remove Yucky Corns And Calluses', 'Predicted Answer: ': 'While calluses typically only look unpleasant and feel rough to the touch, corns —', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8357110023498535], 'recall': [0.8583539128303528], 'f1': [0.8468811511993408], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.10638297872340426}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the war between traffic-weary homeowners and Waze about?\n",
      "{'Reference Answer: ': 'For some drivers, their app-inspired shortcut became a permanent route.', 'Predicted Answer: ': 'the disembodied female voice he could hear through the occasional open window saying, \"Contin', 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8097130060195923], 'recall': [0.8401047587394714], 'f1': [0.8246289491653442], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.032051282051282055}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the reason for the recall of ham from Costco and Sam's Club?\n",
      "{'Reference Answer: ': 'pieces of rubber material embedded in the meat', 'Predicted Answer: ': 'Shockingly, those un-chewable portions were covered in pieces of rubber material', 'BLEU Score: ': {'google_bleu': 0.2619047619047619}, 'Bert Score: ': {'precision': [0.8520948886871338], 'recall': [0.8935619592666626], 'f1': [0.8723359107971191], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.4172413793103449}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What has the Moon not done in nearly half a century?\n",
      "{'Reference Answer: ': 'full moon on the same day as the summer solstice', 'Predicted Answer: ': 'The full moon of June, also known as the \"Strawberry Moon,\" will occur', 'BLEU Score: ': {'google_bleu': 0.0967741935483871}, 'Bert Score: ': {'precision': [0.8609129786491394], 'recall': [0.8714309334754944], 'f1': [0.8661400079727173], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.22822085889570554}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the downside of drinking sparkling water?\n",
      "{'Reference Answer: ': 'the greatest potential health drawback of consuming bottled sparkling water is missing out on the benefit of fluoride when you drink it instead of fluoridated tap water', 'Predicted Answer: ': 'low pH (a measure of acidity), also have the potential to erode tooth enamel', 'BLEU Score: ': {'google_bleu': 0.029411764705882353}, 'Bert Score: ': {'precision': [0.8293424248695374], 'recall': [0.8252003192901611], 'f1': [0.8272662162780762], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.08333333333333334}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How did this 27-year-old make $1 million last year?\n",
      "{'Reference Answer: ': 'Her ticket out of debt and into financial freedom has been her blog, Making Sense of Cents, where she offers tips on saving and making money   and publishes income reports.', 'Predicted Answer: ': '2013 was the year she made $1 million, or about a quarter of that amount.', 'BLEU Score: ': {'google_bleu': 0.031746031746031744}, 'Bert Score: ': {'precision': [0.8481447100639343], 'recall': [0.8405561447143555], 'f1': [0.8443333506584167], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.10256410256410255}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What does it mean to be caught \"Doping\" at the Olympics?\n",
      "{'Reference Answer: ': 'taking a banned or illegal substance in order to improve performance', 'Predicted Answer: ': 'the World Anti-Doping Agency is \"disappointed\" in the International Olympic Committee for', 'BLEU Score: ': {'google_bleu': 0.02}, 'Bert Score: ': {'precision': [0.8135354518890381], 'recall': [0.8099030256271362], 'f1': [0.8117151856422424], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0364963503649635}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the trick that will keep food from spoiling?\n",
      "{'Reference Answer: ': 'move all the perishable older goods to the front and place the newer groceries behind them.', 'Predicted Answer: ': 'the FIFO method of sorting your groceries', 'BLEU Score: ': {'google_bleu': 0.03225806451612903}, 'Bert Score: ': {'precision': [0.8502375483512878], 'recall': [0.844789981842041], 'f1': [0.8475049734115601], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.125}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What was the reason for the couple to call off their wedding?\n",
      "{'Reference Answer: ': 'The woman strongly believed that PM Narendra Modi is responsible for poverty and other terrible conditions in our country. Whereas the husband felt otherwise. He strongly believed that NaMo is doing his best to fix everything, gradually.', 'Predicted Answer: ': 'He strongly believed that NaMo is doing his best to fix everything, gradually.', 'BLEU Score: ': {'google_bleu': 0.34177215189873417}, 'Bert Score: ': {'precision': [0.930749237537384], 'recall': [0.8868275284767151], 'f1': [0.9082577228546143], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8521464646464647}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the link between the kidnapped teen's mom and the suspect?\n",
      "{'Reference Answer: ': 'arrested in a 2012 marijuana trafficking bust', 'Predicted Answer: ': 'Maria Corral and suspect Juan Alberto Contreras-Rodriguez', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.791900098323822], 'recall': [0.832850456237793], 'f1': [0.8118591904640198], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the impact of Brexit on UK citizens who have already booked their summer holidays abroad?\n",
      "{'Reference Answer: ': \"If you've booked a holiday, but are yet to exchange your pounds for a foreign currency, you're going to be a victim of Britain leaving the EU I'm afraid. And your flights look like they're going to go up in price, too.\", 'Predicted Answer: ': \"I'm afraid that if you're not trading your pounds for a foreign currency\", 'BLEU Score: ': {'google_bleu': 0.12087912087912088}, 'Bert Score: ': {'precision': [0.8925988674163818], 'recall': [0.8541300892829895], 'f1': [0.8729408979415894], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5495818399044206}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What has Emma Roberts done now?\n",
      "{'Reference Answer: ': 'is still wearing her updo braids TWO DAYS after debuting the glamorous look at the Met Gala', 'Predicted Answer: ': 'Roberts changed her clothes and her sunglasses, but not her braids. They remain.', 'BLEU Score: ': {'google_bleu': 0.03225806451612903}, 'Bert Score: ': {'precision': [0.8795977830886841], 'recall': [0.8456078171730042], 'f1': [0.8622679114341736], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.062111801242236024}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What makes 2017 a good year to visit Kathmandu?\n",
      "{'Reference Answer: ': 'Every rupee spent in hotels and restaurants, shops, taxis or temples, is helping Kathmandu back on to its feet', 'Predicted Answer: ': 'two year anniversary of the Nepal earthquake approaching', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8478349447250366], 'recall': [0.8218231201171875], 'f1': [0.8346264362335205], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the word \"f-word\"?\n",
      "{'Reference Answer: ': '\"The Wolf of Wall Street\" features a lot of swear words. According to Vulture, there are 569 variations on the f-word alone', 'Predicted Answer: ': 'According to Vulture, there are 569 variations on the f-word alone,', 'BLEU Score: ': {'google_bleu': 0.42857142857142855}, 'Bert Score: ': {'precision': [0.9534212350845337], 'recall': [0.9108059406280518], 'f1': [0.9316264986991882], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8326048951048953}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the secret reason that Apple might be killing the iPhone headphone jack?\n",
      "{'Reference Answer: ': \"If we're being honest, this probably won't be the most exciting iPhone release we've seen\", 'Predicted Answer: ': \"iPhone 7's headphone jack is dead\", 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8458312153816223], 'recall': [0.8311944007873535], 'f1': [0.8384490013122559], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06097560975609756}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happens when schools let transgender students use the bathroom they want?\n",
      "{'Reference Answer: ': 'The school created two \"all-gender,\" single-stall restrooms in February. Students can still choose what works best for them.', 'Predicted Answer: ': 'no cohesive policy exists nationwide on the issue of bathroom access for transgender students', 'BLEU Score: ': {'google_bleu': 0.011627906976744186}, 'Bert Score: ': {'precision': [0.8743619918823242], 'recall': [0.8679050803184509], 'f1': [0.8711215257644653], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1342281879194631}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the name of the song that Adele's \"Hello\" video smashed?\n",
      "{'Reference Answer: ': 'fastest video to break 1 billion views', 'Predicted Answer: ': 'hit song \"Hello\" became the fastest video to break 1 billion views on YouTube', 'BLEU Score: ': {'google_bleu': 0.3793103448275862}, 'Bert Score: ': {'precision': [0.894183337688446], 'recall': [0.9475089907646179], 'f1': [0.9200741648674011], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.46290039194485744}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the name of the UFC fighter who was involved in an armed robbery shootout?\n",
      "{'Reference Answer: ': 'Shevchenko’s coach, Pavel Fedotov, was armed with a gun and decided to take matters into his own hands. Firing at the group of men, Fedotov allegedly killed one of the men. He was then shot himself in the stomach', 'Predicted Answer: ': 'a group of men stormed the place and demanded that any money on the premises', 'BLEU Score: ': {'google_bleu': 0.058823529411764705}, 'Bert Score: ': {'precision': [0.8674737811088562], 'recall': [0.8316559791564941], 'f1': [0.8491873741149902], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.22099447513812157}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the claim in the sentence?\n",
      "{'Reference Answer: ': \"the reactor is a region of natural uranium within the Earth's crust, found in Okla, Gabon. Uranium is naturally radioactive, and the conditions in this rocky area happened to be just right to cook up some nuclear reactions.\", 'Predicted Answer: ': \"region of natural uranium within the Earth's crust\", 'BLEU Score: ': {'google_bleu': 0.1566265060240964}, 'Bert Score: ': {'precision': [0.927600085735321], 'recall': [0.8503533005714417], 'f1': [0.887298583984375], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6582716049382717}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the meaning of the sentence?\n",
      "{'Reference Answer: ': 'These services offer a way for us to build monuments to ourselves. They let us combine our curated memories and experiences with all our messy data — the texts and tweets and \"Likes\" and photos — and organize it into something that we hope will let our loved ones and future generations actually understand something about who we were.', 'Predicted Answer: ': 'By transferring our minds into machines we could live forever, unmoored from the fee', 'BLEU Score: ': {'google_bleu': 0.016260162601626018}, 'Bert Score: ': {'precision': [0.8513835072517395], 'recall': [0.8241275548934937], 'f1': [0.8375337719917297], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.12626262626262627}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What happens after you catch every Pokémon?\n",
      "{'Reference Answer: ': 'Marriott Rewards has offered to sponsor Johnson to go to Europe, Japan and Australia to catch the regionally based Pokémon and finish his collection', 'Predicted Answer: ': 'Off on an international trip to catch the Pokémon elsewhere in the world — underwritten by an', 'BLEU Score: ': {'google_bleu': 0.06382978723404255}, 'Bert Score: ': {'precision': [0.8628313541412354], 'recall': [0.8344703912734985], 'f1': [0.8484139442443848], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.14357053682896379}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the problem with the government trying to grow weed?\n",
      "{'Reference Answer: ': 'Not only is the weed bad, but Sisley claims it was moldy as well', 'Predicted Answer: ': 'The quality of cannabis you can purchase (legally or illegally) in the United States can', 'BLEU Score: ': {'google_bleu': 0.016129032258064516}, 'Bert Score: ': {'precision': [0.8202075958251953], 'recall': [0.8273138999938965], 'f1': [0.8237454295158386], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.029761904761904767}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What should you never say to someone with Obsessive Compulsive Disorder?\n",
      "{'Reference Answer: ': '\"OMG same! I keep my closet perfectly color-coded!\"', 'Predicted Answer: ': '\"OMG same! I keep my closet perfectly color-coded!\"', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9997106481481481}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the most common use of Tinder by college students?\n",
      "{'Reference Answer: ': 'swipe left on Tinder and choose the old-fashioned way', 'Predicted Answer: ': 'college students would swipe left on Tinder and choose the old-fashioned way of finding love', 'BLEU Score: ': {'google_bleu': 0.5555555555555556}, 'Bert Score: ': {'precision': [0.9117664694786072], 'recall': [0.9358376264572144], 'f1': [0.9236452579498291], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6245713305898491}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What did NASA just announce?\n",
      "{'Reference Answer: ': 'its next Mars rover, dubbed Mars 2020, has cleared a massive hurdle that could see it speeding toward the Red Planet in just a few years.', 'Predicted Answer: ': 'it will settle down in the soil of the Red Planet to begin its journey', 'BLEU Score: ': {'google_bleu': 0.08181818181818182}, 'Bert Score: ': {'precision': [0.8731881380081177], 'recall': [0.8443951606750488], 'f1': [0.8585503101348877], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.3116531165311653}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What caused cars to change from being boxy in the 1980s to being curvy in the 1990\n",
      "{'Reference Answer: ': 'largely due to three interrelated factors: European style trends, a government-mandated push for fuel economy, and new technologies that allowed manufacturers to more easily design and create curved shapes.', 'Predicted Answer: ': 'all of the cars look super boxy, especially compared with the curving, rounded', 'BLEU Score: ': {'google_bleu': 0.015873015873015872}, 'Bert Score: ': {'precision': [0.8462841510772705], 'recall': [0.8262279629707336], 'f1': [0.8361358642578125], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0892857142857143}\n"
     ]
    }
   ],
   "source": [
    "_all = {}\n",
    "arr = [{} for i in range(3)]\n",
    "bleu = 0\n",
    "meteor_int = 0\n",
    "bert = 0\n",
    "count = 0\n",
    "\n",
    "for i in range(200):\n",
    "  label = validation_dataset.iloc[i]['labels']\n",
    "  if label == 1:  \n",
    "    question = validation_dataset.iloc[i]['generated_que']\n",
    "    context = validation_dataset.iloc[i]['article']\n",
    "    answer = ' '.join(validation_dataset.iloc[i]['spoiler'])\n",
    "        \n",
    "    print(validation_dataset.iloc[i]['labels'])\n",
    "    ans = predict_answer(context, question, answer)\n",
    "    _all['bleu'] = _all.get('bleu', 0) + ans[\"BLEU Score: \"]['google_bleu']\n",
    "    _all['bert'] = _all.get('bert', 0) + ans['Bert Score: ']['precision'][0]\n",
    "    _all['meteor'] = _all.get('meteor', 0) + ans['Meteor Score: ']\n",
    "\n",
    "\n",
    "    # type = validation_dataset.iloc[i]['labels']\n",
    "    # arr[type]['bleu'] = arr[type].get('bleu',0) + ans[\"BLEU Score: \"]['google_bleu']\n",
    "    # arr[type]['bert'] = arr[type].get('bert',0) + ans[\"Bert Score: \"]['precision'][0]\n",
    "    # arr[type]['meteor'] = arr[type].get('meteor',0) + ans[\"Meteor Score: \"]\n",
    "    # arr[type]['count'] = arr[type].get('count',0) + 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(ans)\n",
    "    if validation_dataset.iloc[i]['labels'] == 2:\n",
    "        continue\n",
    "    count += 1\n",
    "    bleu += ans[\"BLEU Score: \"]['google_bleu']\n",
    "    bert += ans[\"Bert Score: \"]['precision'][0]\n",
    "    meteor_int += ans[\"Meteor Score: \"]\n",
    "    \n",
    "    \n",
    "\n",
    "# print(\" All \" + str(_all['bert']/100))\n",
    "# print(\" Phrase \" + str(arr[0]['bert']/arr[0]['count']))\n",
    "# print(\" Passage \" + str(arr[1]['bert']/arr[1]['count']))\n",
    "# print(\" Multi \" + str(arr[2]['bert']/arr[2]['count']))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc7c6014-ac48-4c9f-a70a-fe27e145a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14608320464180788\n",
      "0.8684057418037864\n",
      "0.27454697136103\n"
     ]
    }
   ],
   "source": [
    "print(bleu/count)\n",
    "print(bert/count)\n",
    "print(meteor_int/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5d0f9-51cc-4c8d-b7fb-2b08b32e69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
