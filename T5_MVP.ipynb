{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d34d4f-c491-4c1a-9fa6-b1a08398b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a61accbde34c0eb50b9e999d718f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579718f1-50eb-488f-b0d9-27ba8a8e8038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 12.1\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "# DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_device(DEVICE)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa4541c-dcf5-4b0e-a996-0fecae619c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 21:51:16.913084: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 21:51:16.954524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 21:51:17.687046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install evaluate\n",
    "# !pip install rouge\n",
    "# !pip install spacy\n",
    "\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import evaluate  # Bleu\n",
    "from nltk.translate import meteor\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07526534-3342-4bdb-9d64-8cc85d39ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    \n",
    "    df = []\n",
    "    df_multi = []\n",
    "    df_phrase = []\n",
    "    df_passage = []\n",
    "    with open('/DATA1/ai20btech11028/vojes_nlp/Data/' + file_name, encoding='utf-8') as f:\n",
    "        for i in f:\n",
    "            i = json.loads(i)\n",
    "                \n",
    "            tweet = i['postText']\n",
    "            article_title = i['targetTitle']\n",
    "            article = ' '.join(i['targetParagraphs'])\n",
    "            spoilers = i['spoiler']\n",
    "            label = i['tags']\n",
    "            keywords = i['targetKeywords']\n",
    "            positions = i['spoilerPositions']\n",
    "            \n",
    "            assert len(tweet) == 1\n",
    "            tweet = tweet[0]\n",
    "            \n",
    "            assert len(label) == 1\n",
    "            label = label[0]\n",
    "            \n",
    "            if label not in ['phrase', 'phrases', 'passage', 'multi']:\n",
    "                print(label)\n",
    "                \n",
    "            assert label in ['phrase', 'phrases', 'passage', 'multi']\n",
    "            \n",
    "            if label == 'phrase' or label == 'phrases':\n",
    "                label = 0\n",
    "            elif label == 'multi':\n",
    "                label = 2\n",
    "            else:\n",
    "                label = 1\n",
    "                \n",
    "            \n",
    "            df += [{'question': tweet , 'context': i['targetParagraphs'], 'article': article_title + article, 'spoiler':spoilers,\n",
    "                    'labels': label, 'keywords':keywords, 'spoilerPositions':positions}]\n",
    "\n",
    "    return pd.DataFrame(df)\n",
    "            \n",
    "    \n",
    "# # test_dataset = load_dataset('test.jsonl')\n",
    "train_dataset = load_dataset('train.jsonl')\n",
    "validation_dataset = load_dataset('validation.jsonl')\n",
    "# print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa58031b-65b1-4969-a461-d19ef5750065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"MateuszW/generated_questions\")\n",
    "\n",
    "genQue_train = dataset['train']['generated_questions']\n",
    "genQue_test = dataset['validation']['generated_questions']\n",
    "# print(genQue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5584164a-49fb-4d3e-8cb9-793ce8b885b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>article</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>labels</th>\n",
       "      <th>keywords</th>\n",
       "      <th>spoilerPositions</th>\n",
       "      <th>generated_que</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[It’ll be just like old times this weekend for...</td>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>[how about that morning we go throw?]</td>\n",
       "      <td>1</td>\n",
       "      <td>new england patriots, ricky doyle, top stories,</td>\n",
       "      <td>[[[3, 151], [3, 186]]]</td>\n",
       "      <td>What did Tom Brady do instead of having dinner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NASA sets date for full recovery of ozone hole</td>\n",
       "      <td>[2070 is shaping up to be a great year for Mot...</td>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>[2070]</td>\n",
       "      <td>0</td>\n",
       "      <td>ozone layer,ozone hole determined by weather,M...</td>\n",
       "      <td>[[[0, 0], [0, 4]]]</td>\n",
       "      <td>What is the date that NASA has set for the ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is what makes employees happy -- and it's...</td>\n",
       "      <td>[Despite common belief, money isn't the key to...</td>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>[intellectual stimulation]</td>\n",
       "      <td>0</td>\n",
       "      <td>employee happiness money,employee happiness in...</td>\n",
       "      <td>[[[1, 186], [1, 210]]]</td>\n",
       "      <td>What makes employees happy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Passion is overrated — 7 work habits you need ...</td>\n",
       "      <td>[It’s common wisdom. Near gospel really, and n...</td>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>[Purpose connects us to something bigger and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>business, work-life, careers</td>\n",
       "      <td>[[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...</td>\n",
       "      <td>What are the 7 work habits that are considered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The perfect way to cook rice so that it's perf...</td>\n",
       "      <td>[Boiling rice may seem simple, but there is a ...</td>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>[in a rice cooker]</td>\n",
       "      <td>0</td>\n",
       "      <td>Quora,users,share,perfect,way,cook,rice</td>\n",
       "      <td>[[[5, 60], [5, 76]]]</td>\n",
       "      <td>What is the best way to cook rice so that it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>[A long time ago in a galaxy far, far away...W...</td>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>[it hasn’t necessarily taken the wind out of Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>Facebook,web video,web video ads,YouTube</td>\n",
       "      <td>[[[7, 50], [7, 118]]]</td>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Cop Is Eating At A Chili's When Teen Hands Him...</td>\n",
       "      <td>[The Kansas City, Kansas Police Department are...</td>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>[It read, \"Thanks for keeping us safe.\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[0, 317], [0, 355]]]</td>\n",
       "      <td>What did the teen give the cop?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[Obama looks decades younger already, but what...</td>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>[1. Anti-wrinkle creams will erase the fine li...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>[[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...</td>\n",
       "      <td>What are the 5 popular myths about visible sig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>You need to see this Twitter account that pred...</td>\n",
       "      <td>[What the HELL?!, 1. Unless you’re somewhere w...</td>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td>[@beyoncefan666]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[[3, 55], [3, 69]]]</td>\n",
       "      <td>What is the purpose of the Twitter account men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>GOP congressman comes out for gay marriage</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.) came out in support...</td>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>[Rep. Charlie Dent (R-Pa.)]</td>\n",
       "      <td>0</td>\n",
       "      <td>lgbt,charlie dent gay marriage,Charlie Dent,pe...</td>\n",
       "      <td>[[[0, 0], [0, 25]]]</td>\n",
       "      <td>What is the name of the GOP congressman who ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1        NASA sets date for full recovery of ozone hole   \n",
       "2     This is what makes employees happy -- and it's...   \n",
       "3     Passion is overrated — 7 work habits you need ...   \n",
       "4     The perfect way to cook rice so that it's perf...   \n",
       "...                                                 ...   \n",
       "3195  Has Facebook's video explosion completely shak...   \n",
       "3196  Cop Is Eating At A Chili's When Teen Hands Him...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  You need to see this Twitter account that pred...   \n",
       "3199         GOP congressman comes out for gay marriage   \n",
       "\n",
       "                                                context  \\\n",
       "0     [It’ll be just like old times this weekend for...   \n",
       "1     [2070 is shaping up to be a great year for Mot...   \n",
       "2     [Despite common belief, money isn't the key to...   \n",
       "3     [It’s common wisdom. Near gospel really, and n...   \n",
       "4     [Boiling rice may seem simple, but there is a ...   \n",
       "...                                                 ...   \n",
       "3195  [A long time ago in a galaxy far, far away...W...   \n",
       "3196  [The Kansas City, Kansas Police Department are...   \n",
       "3197  [Obama looks decades younger already, but what...   \n",
       "3198  [What the HELL?!, 1. Unless you’re somewhere w...   \n",
       "3199  [Rep. Charlie Dent (R-Pa.) came out in support...   \n",
       "\n",
       "                                                article  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                                spoiler  labels  \\\n",
       "0                 [how about that morning we go throw?]       1   \n",
       "1                                                [2070]       0   \n",
       "2                            [intellectual stimulation]       0   \n",
       "3     [Purpose connects us to something bigger and i...       2   \n",
       "4                                    [in a rice cooker]       0   \n",
       "...                                                 ...     ...   \n",
       "3195  [it hasn’t necessarily taken the wind out of Y...       1   \n",
       "3196           [It read, \"Thanks for keeping us safe.\"]       1   \n",
       "3197  [1. Anti-wrinkle creams will erase the fine li...       2   \n",
       "3198                                   [@beyoncefan666]       0   \n",
       "3199                        [Rep. Charlie Dent (R-Pa.)]       0   \n",
       "\n",
       "                                               keywords  \\\n",
       "0       new england patriots, ricky doyle, top stories,   \n",
       "1     ozone layer,ozone hole determined by weather,M...   \n",
       "2     employee happiness money,employee happiness in...   \n",
       "3                          business, work-life, careers   \n",
       "4               Quora,users,share,perfect,way,cook,rice   \n",
       "...                                                 ...   \n",
       "3195           Facebook,web video,web video ads,YouTube   \n",
       "3196                                               None   \n",
       "3197                                                      \n",
       "3198                                                      \n",
       "3199  lgbt,charlie dent gay marriage,Charlie Dent,pe...   \n",
       "\n",
       "                                       spoilerPositions  \\\n",
       "0                                [[[3, 151], [3, 186]]]   \n",
       "1                                    [[[0, 0], [0, 4]]]   \n",
       "2                                [[[1, 186], [1, 210]]]   \n",
       "3     [[[11, 25], [11, 101]], [[17, 56], [17, 85]], ...   \n",
       "4                                  [[[5, 60], [5, 76]]]   \n",
       "...                                                 ...   \n",
       "3195                              [[[7, 50], [7, 118]]]   \n",
       "3196                             [[[0, 317], [0, 355]]]   \n",
       "3197  [[[6, 0], [6, 73]], [[10, 0], [10, 109]], [[14...   \n",
       "3198                               [[[3, 55], [3, 69]]]   \n",
       "3199                                [[[0, 0], [0, 25]]]   \n",
       "\n",
       "                                          generated_que  \n",
       "0     What did Tom Brady do instead of having dinner...  \n",
       "1     What is the date that NASA has set for the ful...  \n",
       "2                           What makes employees happy?  \n",
       "3     What are the 7 work habits that are considered...  \n",
       "4     What is the best way to cook rice so that it's...  \n",
       "...                                                 ...  \n",
       "3195  Has Facebook's video explosion completely shak...  \n",
       "3196                    What did the teen give the cop?  \n",
       "3197  What are the 5 popular myths about visible sig...  \n",
       "3198  What is the purpose of the Twitter account men...  \n",
       "3199  What is the name of the GOP congressman who ca...  \n",
       "\n",
       "[3200 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"generated_que\"] = list(genQue_train)\n",
    "validation_dataset[\"generated_que\"] = list(genQue_test)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ec5c90-2cb9-4d5a-8cfb-29592515713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an question paired with a context for which generate answer.Write an answer as short as possible (max 5 words). Use only words from context.\n",
      "\n",
      "### Question:\n",
      "{question}\n",
      "\n",
      "### Context:\n",
      "{context}\n",
      "\n",
      "### Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPT = {\n",
    "        0: (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write an answer as short as possible (max 5 words). Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{question}\\n\\n### Context:\\n{context}\\n\\n### Answer: [MASK]\\n\"\n",
    "        ),\n",
    "        \"passage\": (\n",
    "            \"Below is an question paired with a context for which generate a passage  answer.\"\n",
    "            \"Write the most suitable answer which will be from one to three sentences. Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{question}\\n\\n### Context:\\n{context}\\n\\n### Answer: [MASK]\\n\"\n",
    "        ),\n",
    "        \"multi\": (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write an answer which is multi part that means it contains multiple \"\n",
    "            \"phrase or sentences from given text. The answers are spanned through paragraphs, check for all answers. Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{question}\\n\\n### Context:\\n{context}\\n\\n### Answer:[MASK]\\n\"\n",
    "        ),\n",
    "        }\n",
    "\n",
    "print(PROMPT[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab52a82-5f1c-44a3-af18-51dba8850663",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = T5TokenizerFast.from_pretrained(\"google-t5/t5-base\")\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-base\", return_dict=True).to(DEVICE)\n",
    "\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.0001)\n",
    "Q_LEN = 256   # Question Length\n",
    "T_LEN = 256  # Target Length\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa17177-765e-42cc-b0f1-70c0557dd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting context, question, and answers from the dataset\n",
    "\n",
    "def prepare_data(train_dataset):\n",
    "    articles = []\n",
    "    \n",
    "    for i in range(len(train_dataset)):\n",
    "        clickbait = train_dataset.iloc[i]\n",
    "        # if clickbait['labels'] == 1:\n",
    "        context = clickbait['article']\n",
    "        question = clickbait['generated_que']\n",
    "        label = clickbait['labels']\n",
    "        answer = ' '.join(clickbait['spoiler'])\n",
    "\n",
    "        inputs = {\"context\": context, \"question\": question, \"answer\": answer, \"label\":label}\n",
    "\n",
    "        articles.append(inputs)\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05423bee-452f-42ce-ab8b-982884df6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(train_dataset)\n",
    "\n",
    "# Create a Dataframe\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3f2bebb-0ac4-44f0-8f29-346bad5c5f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
       "      <td>What did Tom Brady do instead of having dinner...</td>\n",
       "      <td>how about that morning we go throw?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hole In Ozone Layer Expected To Make Full Reco...</td>\n",
       "      <td>What is the date that NASA has set for the ful...</td>\n",
       "      <td>2070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intellectual Stimulation Trumps Money For Empl...</td>\n",
       "      <td>What makes employees happy?</td>\n",
       "      <td>intellectual stimulation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‘Follow your passion’ is wrong, here are 7 hab...</td>\n",
       "      <td>What are the 7 work habits that are considered...</td>\n",
       "      <td>Purpose connects us to something bigger and in...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Revealed: The perfect way to cook rice so that...</td>\n",
       "      <td>What is the best way to cook rice so that it's...</td>\n",
       "      <td>in a rice cooker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Facebook Video Surging, But YouTube Still Offe...</td>\n",
       "      <td>Has Facebook's video explosion completely shak...</td>\n",
       "      <td>it hasn’t necessarily taken the wind out of Yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>Cop is eating at Chili's when teen hands him f...</td>\n",
       "      <td>What did the teen give the cop?</td>\n",
       "      <td>It read, \"Thanks for keeping us safe.\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>5 popular myths about visible signs of aging t...</td>\n",
       "      <td>What are the 5 popular myths about visible sig...</td>\n",
       "      <td>1. Anti-wrinkle creams will erase the fine lin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>WTF, It Looks Like This Twitter Account \"Predi...</td>\n",
       "      <td>What is the purpose of the Twitter account men...</td>\n",
       "      <td>@beyoncefan666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>Pennsylvania GOP Rep. Charlie Dent Comes Out F...</td>\n",
       "      <td>What is the name of the GOP congressman who ca...</td>\n",
       "      <td>Rep. Charlie Dent (R-Pa.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
       "1     Hole In Ozone Layer Expected To Make Full Reco...   \n",
       "2     Intellectual Stimulation Trumps Money For Empl...   \n",
       "3     ‘Follow your passion’ is wrong, here are 7 hab...   \n",
       "4     Revealed: The perfect way to cook rice so that...   \n",
       "...                                                 ...   \n",
       "3195  Facebook Video Surging, But YouTube Still Offe...   \n",
       "3196  Cop is eating at Chili's when teen hands him f...   \n",
       "3197  5 popular myths about visible signs of aging t...   \n",
       "3198  WTF, It Looks Like This Twitter Account \"Predi...   \n",
       "3199  Pennsylvania GOP Rep. Charlie Dent Comes Out F...   \n",
       "\n",
       "                                               question  \\\n",
       "0     What did Tom Brady do instead of having dinner...   \n",
       "1     What is the date that NASA has set for the ful...   \n",
       "2                           What makes employees happy?   \n",
       "3     What are the 7 work habits that are considered...   \n",
       "4     What is the best way to cook rice so that it's...   \n",
       "...                                                 ...   \n",
       "3195  Has Facebook's video explosion completely shak...   \n",
       "3196                    What did the teen give the cop?   \n",
       "3197  What are the 5 popular myths about visible sig...   \n",
       "3198  What is the purpose of the Twitter account men...   \n",
       "3199  What is the name of the GOP congressman who ca...   \n",
       "\n",
       "                                                 answer  label  \n",
       "0                   how about that morning we go throw?      1  \n",
       "1                                                  2070      0  \n",
       "2                              intellectual stimulation      0  \n",
       "3     Purpose connects us to something bigger and in...      2  \n",
       "4                                      in a rice cooker      0  \n",
       "...                                                 ...    ...  \n",
       "3195  it hasn’t necessarily taken the wind out of Yo...      1  \n",
       "3196             It read, \"Thanks for keeping us safe.\"      1  \n",
       "3197  1. Anti-wrinkle creams will erase the fine lin...      2  \n",
       "3198                                     @beyoncefan666      0  \n",
       "3199                          Rep. Charlie Dent (R-Pa.)      0  \n",
       "\n",
       "[3200 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57345d6a-743a-4317-8894-88e04f377ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    def __init__(self, tokenizer, dataframe, q_len, t_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.q_len = q_len\n",
    "        self.t_len = t_len\n",
    "        self.data = dataframe\n",
    "        self.questions = self.data[\"question\"]\n",
    "        self.context = self.data[\"context\"]\n",
    "        self.answer = self.data['answer']\n",
    "        self.label = self.data['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.context[idx]\n",
    "        answer = self.answer[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        PROMPT = {\n",
    "        0: (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write an answer as short as possible (max 5 words). Use only words from context.\\n\\n\"\n",
    "            \"### The clickbait Question:\\n{questions}\\n\\n### The article Context:\\n{contexts}\\n\\n### The spoiler of the clickbait is [MASK]\\n\"\n",
    "        ),\n",
    "        1: (\n",
    "            \"Below is an question paired with a context for which generate a answer.\"\n",
    "            \"Write a complete answer  which will be from one to three sentences. Complete the answer properly. Use only words from context.\\n\\n\"\n",
    "            \"### The clickbait Question:\\n{questions}\\n\\n### The article Context:\\n{contexts}\\n\\n### The spoiler of the clickbait is [MASK]\\n\"\n",
    "        ),\n",
    "        2: (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write the spoiler which is multi part that means it contains multiple \"\n",
    "            \"phrase or sentences as spoilers from given text. The spoilers are spanned through paragraphs, check for all spoilers. Use only words from context.\\n\\n\"\n",
    "           \"### The clickbait Question:\\n{questions}\\n\\n### The article Context:\\n{contexts}\\n\\n### The spoiler of the clickbait is [MASK]\\n\"\n",
    "        ),\n",
    "        }\n",
    "\n",
    "\n",
    "        prompt = PROMPT[label].format(questions=question, contexts=context)\n",
    "        \n",
    "        question_tokenized = self.tokenizer(prompt, max_length=self.q_len, padding=\"max_length\",\n",
    "                                                    truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        answer_tokenized = self.tokenizer(answer, max_length=self.t_len, padding=\"max_length\", \n",
    "                                          truncation=True, pad_to_max_length=True, add_special_tokens=True)\n",
    "        \n",
    "        labels = torch.tensor(answer_tokenized[\"input_ids\"], dtype=torch.long)\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(question_tokenized[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(question_tokenized[\"attention_mask\"], dtype=torch.long),\n",
    "            \"labels\": labels,\n",
    "            \"decoder_attention_mask\": torch.tensor(answer_tokenized[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2ca788-6bb8-4fa1-a106-3294c1e63ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_sampler = RandomSampler(train_data.index)\n",
    "val_sampler = RandomSampler(val_data.index)\n",
    "\n",
    "qa_dataset = QA_Dataset(TOKENIZER, data, Q_LEN, T_LEN)\n",
    "\n",
    "train_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "val_loader = DataLoader(qa_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b24eb27d-52e9-4f8b-90ab-6bbc2b4c5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:21<00:00,  1.96it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20 -> Train loss: 2.360201086103916\tValidation loss: 1.705070897936821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/20 -> Train loss: 2.1603990003466604\tValidation loss: 1.4913622833788396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:23<00:00,  1.92it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/20 -> Train loss: 2.016611537958185\tValidation loss: 1.2936197793732087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.95it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/20 -> Train loss: 1.8972807224839925\tValidation loss: 1.1139359843917191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/20 -> Train loss: 1.7937853940203785\tValidation loss: 0.9680611748993396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20 -> Train loss: 1.7005142709550758\tValidation loss: 0.8463895115535707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:23<00:00,  1.91it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/20 -> Train loss: 1.6136251462091293\tValidation loss: 0.7450131986955447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:23<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/20 -> Train loss: 1.5370714524877258\tValidation loss: 0.6628465875750408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/20 -> Train loss: 1.4665682796802786\tValidation loss: 0.5952814306197171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:23<00:00,  1.92it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20 -> Train loss: 1.3998196261911653\tValidation loss: 0.5394573699764442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.95it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/20 -> Train loss: 1.337460765477524\tValidation loss: 0.4926216102014719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:20<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20 -> Train loss: 1.2807889511207273\tValidation loss: 0.4531610974750947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20 -> Train loss: 1.2273054328299342\tValidation loss: 0.4194139601489251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.95it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:20<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/20 -> Train loss: 1.1769882628012316\tValidation loss: 0.39014239465458167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:21<00:00,  1.95it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20 -> Train loss: 1.1296687571999307\tValidation loss: 0.3647193974080922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/20 -> Train loss: 1.0860240611888003\tValidation loss: 0.3424706796456121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.95it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20 -> Train loss: 1.0441411393105655\tValidation loss: 0.32265160331521386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.94it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/20 -> Train loss: 1.0050651161426989\tValidation loss: 0.3050339497789941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:21<00:00,  1.96it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 -> Train loss: 0.9685735204073257\tValidation loss: 0.2891603490382917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|███████████████████████████████████████████████████████████████| 160/160 [01:22<00:00,  1.93it/s]\n",
      "Validation batches: 100%|███████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 -> Train loss: 0.934653268851107\tValidation loss: 0.2748656421733904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "train_batch_count = 0\n",
    "val_batch_count = 0\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        train_batch_count += 1\n",
    "    \n",
    "    #Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "\n",
    "        outputs = MODEL(\n",
    "                          input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          labels=labels,\n",
    "                          decoder_attention_mask=decoder_attention_mask\n",
    "                        )\n",
    "\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        val_loss += outputs.loss.item()\n",
    "        val_batch_count += 1\n",
    "        \n",
    "    print(f\"{epoch+1}/{epochs} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14332f5-eb0b-47d5-8a09-933d6e341b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('qa_tokenizer/tokenizer_config.json',\\n 'qa_tokenizer/special_tokens_map.json',\\n 'qa_tokenizer/spiece.model',\\n'qa_tokenizer/added_tokens.json',\\n'qa_tokenizer/tokenizer.json')\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL.save_pretrained(\"qa_model_50_epochs\")\n",
    "TOKENIZER.save_pretrained(\"qa_tokenizer_50_epochs\")\n",
    "\n",
    "# Saved files\n",
    "\"\"\"('qa_tokenizer/tokenizer_config.json',\n",
    " 'qa_tokenizer/special_tokens_map.json',\n",
    " 'qa_tokenizer/spiece.model',\n",
    "'qa_tokenizer/added_tokens.json',\n",
    "'qa_tokenizer/tokenizer.json')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "902fd7ef-29de-4470-af3d-d4a2106b6fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answer(context, question, label, ref_answer=None):\n",
    "    PROMPT = {\n",
    "        0: (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write an answer as short as possible (max 5 words). Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{questions}\\n\\n### Context:\\n{contexts}\\n\\n### Answer:\\n\"\n",
    "        ),\n",
    "        1: (\n",
    "            \"Below is an question paired with a context for which generate a answer.\"\n",
    "            \"Write a complete answer which will be from one to three sentences. Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{questions}\\n\\n### Context:\\n{contexts}\\n\\n### Answer:\\n\"\n",
    "        ),\n",
    "        2: (\n",
    "            \"Below is an question paired with a context for which generate answer.\"\n",
    "            \"Write an answer which is multi part that means it contains multiple \"\n",
    "            \"phrase or sentences from given text. The answers are spanned through paragraphs, check for all answers. Use only words from context.\\n\\n\"\n",
    "            \"### Question:\\n{questions}\\n\\n### Context:\\n{contexts}\\n\\n### Answer:\\n\"\n",
    "        ),\n",
    "        }\n",
    "\n",
    "    # print(label)\n",
    "    prompt = PROMPT[label].format(questions=question, contexts=context)\n",
    "        \n",
    "    inputs = TOKENIZER(prompt, max_length=Q_LEN, padding=\"max_length\", truncation=True, add_special_tokens=True)\n",
    "    \n",
    "    input_ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "    attention_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).to(DEVICE).unsqueeze(0)\n",
    "\n",
    "    outputs = MODEL.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "  \n",
    "    predicted_answer = TOKENIZER.decode(outputs.flatten(), skip_special_tokens=True)\n",
    "    \n",
    "    if ref_answer:\n",
    "        # Load the Bleu metric\n",
    "        bleu = evaluate.load(\"google_bleu\")\n",
    "        score = bleu.compute(predictions=[predicted_answer], \n",
    "                            references=[ref_answer])\n",
    "        bert = evaluate.load(\"bertscore\")\n",
    "\n",
    "        bert_score = bert.compute(predictions=[predicted_answer], references=[ref_answer], lang='en')\n",
    "        ref_token = nltk.word_tokenize(predicted_answer)\n",
    "        pre_token = nltk.word_tokenize(ref_answer)\n",
    "        # print(ref_token)\n",
    "        # print(pre_token)\n",
    "        meteor_score = meteor([ref_token], pre_token)\n",
    "\n",
    "        ref_token = nltk.word_tokenize(predicted_answer)\n",
    "        pre_token = nltk.word_tokenize(ref_answer)\n",
    "        # print(ref_token)\n",
    "        # print(pre_token)\n",
    "        meteor_score = meteor([ref_token], pre_token)\n",
    "    \n",
    "        print(\"Question: \\n\", question)\n",
    "        return {\n",
    "            \"Reference Answer: \": ref_answer, \n",
    "            \"Predicted Answer: \": predicted_answer, \n",
    "            \"BLEU Score: \": score,\n",
    "            \"Bert Score: \": bert_score ,\n",
    "            \"Meteor Score: \": meteor_score\n",
    "        }\n",
    "    else:\n",
    "        return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f40d2bce-13c0-4cde-a476-e51d4f1f06c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>article</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>labels</th>\n",
       "      <th>keywords</th>\n",
       "      <th>spoilerPositions</th>\n",
       "      <th>generated_que</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Five Nights at Freddy’s Sequel Delayed for Wei...</td>\n",
       "      <td>[Five Nights at Freddy’s creator Scott Cawthon...</td>\n",
       "      <td>Five Nights at Freddy’s Sequel Delayed for Wei...</td>\n",
       "      <td>[some of the plot elements are so disturbing t...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[2, 158], [2, 236]]]</td>\n",
       "      <td>What is the reason for the delay of the sequel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Arizona Sheriff Joe Arpaio’s fate could ha...</td>\n",
       "      <td>[© REUTERS/Laura Segall Maricopa County Sherif...</td>\n",
       "      <td>Why Arizona Sheriff Joe Arpaio’s fate could ha...</td>\n",
       "      <td>[\"intentionally\", could transform a court case...</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[0, 197], [0, 212]], [[0, 215], [0, 328]]]</td>\n",
       "      <td>What is the word that could determine the fate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here’s how much you should be tipping your hai...</td>\n",
       "      <td>[Here’s how much you should be tipping your ha...</td>\n",
       "      <td>Here’s how much you should be tipping your hai...</td>\n",
       "      <td>[20%]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>[[[3, 58], [3, 61]]]</td>\n",
       "      <td>How much should you be tipping your hairdresser?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Harry Potter\" alums reunite for new movie</td>\n",
       "      <td>[The mythology of punk music's evolution can b...</td>\n",
       "      <td>Alan Rickman &amp; Rupert Grint On 'CBGB,' Reuniti...</td>\n",
       "      <td>[Alan Rickman &amp; Rupert Grint, CBGB]</td>\n",
       "      <td>2</td>\n",
       "      <td>Alan Rickman,Hilly Kristal,new rupert grint mo...</td>\n",
       "      <td>[[[-1, 0], [-1, 27]], [[0, 98], [0, 102]]]</td>\n",
       "      <td>What is the name of the new movie in which \"Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man swallowed a microSD card and you won't b...</td>\n",
       "      <td>[PetaPixel is one of my favorite blogs. The wr...</td>\n",
       "      <td>Man swallowed a microSD card and you won't bel...</td>\n",
       "      <td>[a man who swallowed a 64GB microSD card and t...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>[[[1, 34], [1, 108]]]</td>\n",
       "      <td>What happened next?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>This is what happens when you leave a hotel cl...</td>\n",
       "      <td>[Instead of encountering a mound of dirty towe...</td>\n",
       "      <td>This Is What Happens When You Leave A Hotel Cl...</td>\n",
       "      <td>[The video below shows the stunned cleaner ini...</td>\n",
       "      <td>1</td>\n",
       "      <td>givebackfilms,give back films,video,random act...</td>\n",
       "      <td>[[[3, 0], [3, 150]]]</td>\n",
       "      <td>What happens when you leave a hotel cleaner a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>This Texas GOP elector announces that he won't...</td>\n",
       "      <td>[A Republican elector in Texas says he will no...</td>\n",
       "      <td>Texas GOP elector announces he won't vote for ...</td>\n",
       "      <td>[Christopher Suprun]</td>\n",
       "      <td>0</td>\n",
       "      <td>donald trump, texas, electoral college, faithl...</td>\n",
       "      <td>[[[1, 45], [1, 63]]]</td>\n",
       "      <td>What is the name of the Texas GOP elector who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>This beauty queen cured her acne with one diet...</td>\n",
       "      <td>[Her inspirational journey is encouraging othe...</td>\n",
       "      <td>UK beauty queen cured her severe acne with one...</td>\n",
       "      <td>[Rachel Crawley, High fat vegan plant based di...</td>\n",
       "      <td>2</td>\n",
       "      <td>acne, Skincare, beauty, Beauty pageant, Dermat...</td>\n",
       "      <td>[[[2, 144], [2, 158]], [[6, 56], [6, 124]]]</td>\n",
       "      <td>What diet change cured the beauty queen's acne?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>WikiLeaks' Julian Assange Reported Dead</td>\n",
       "      <td>[On 16 October 2016, WikiLeaks posted a series...</td>\n",
       "      <td>WikiLeaks’ Julian Assange Isn’t Dead, Just Off...</td>\n",
       "      <td>[Julian Assange’s internet link has been inten...</td>\n",
       "      <td>1</td>\n",
       "      <td>dead man's switch, julian assange, wikileaks</td>\n",
       "      <td>[[[11, 0], [11, 78]]]</td>\n",
       "      <td>What is the meaning of the sentence?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Original \"Law &amp;amp; Order: SVU\" cast member le...</td>\n",
       "      <td>[Richard Belzer is leaving \"Law &amp; Order: SVU.\"...</td>\n",
       "      <td>Richard Belzer Leaving 'Law &amp; Order: SVU': Mun...</td>\n",
       "      <td>[Richard Belzer]</td>\n",
       "      <td>0</td>\n",
       "      <td>TV Canada,richard belzer leaving law and order...</td>\n",
       "      <td>[[[0, 0], [0, 14]]]</td>\n",
       "      <td>What is the name of the original \"Law &amp; Order:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Five Nights at Freddy’s Sequel Delayed for Wei...   \n",
       "1    Why Arizona Sheriff Joe Arpaio’s fate could ha...   \n",
       "2    Here’s how much you should be tipping your hai...   \n",
       "3           \"Harry Potter\" alums reunite for new movie   \n",
       "4    A man swallowed a microSD card and you won't b...   \n",
       "..                                                 ...   \n",
       "795  This is what happens when you leave a hotel cl...   \n",
       "796  This Texas GOP elector announces that he won't...   \n",
       "797  This beauty queen cured her acne with one diet...   \n",
       "798            WikiLeaks' Julian Assange Reported Dead   \n",
       "799  Original \"Law &amp; Order: SVU\" cast member le...   \n",
       "\n",
       "                                               context  \\\n",
       "0    [Five Nights at Freddy’s creator Scott Cawthon...   \n",
       "1    [© REUTERS/Laura Segall Maricopa County Sherif...   \n",
       "2    [Here’s how much you should be tipping your ha...   \n",
       "3    [The mythology of punk music's evolution can b...   \n",
       "4    [PetaPixel is one of my favorite blogs. The wr...   \n",
       "..                                                 ...   \n",
       "795  [Instead of encountering a mound of dirty towe...   \n",
       "796  [A Republican elector in Texas says he will no...   \n",
       "797  [Her inspirational journey is encouraging othe...   \n",
       "798  [On 16 October 2016, WikiLeaks posted a series...   \n",
       "799  [Richard Belzer is leaving \"Law & Order: SVU.\"...   \n",
       "\n",
       "                                               article  \\\n",
       "0    Five Nights at Freddy’s Sequel Delayed for Wei...   \n",
       "1    Why Arizona Sheriff Joe Arpaio’s fate could ha...   \n",
       "2    Here’s how much you should be tipping your hai...   \n",
       "3    Alan Rickman & Rupert Grint On 'CBGB,' Reuniti...   \n",
       "4    Man swallowed a microSD card and you won't bel...   \n",
       "..                                                 ...   \n",
       "795  This Is What Happens When You Leave A Hotel Cl...   \n",
       "796  Texas GOP elector announces he won't vote for ...   \n",
       "797  UK beauty queen cured her severe acne with one...   \n",
       "798  WikiLeaks’ Julian Assange Isn’t Dead, Just Off...   \n",
       "799  Richard Belzer Leaving 'Law & Order: SVU': Mun...   \n",
       "\n",
       "                                               spoiler  labels  \\\n",
       "0    [some of the plot elements are so disturbing t...       1   \n",
       "1    [\"intentionally\", could transform a court case...       2   \n",
       "2                                                [20%]       0   \n",
       "3                  [Alan Rickman & Rupert Grint, CBGB]       2   \n",
       "4    [a man who swallowed a 64GB microSD card and t...       1   \n",
       "..                                                 ...     ...   \n",
       "795  [The video below shows the stunned cleaner ini...       1   \n",
       "796                               [Christopher Suprun]       0   \n",
       "797  [Rachel Crawley, High fat vegan plant based di...       2   \n",
       "798  [Julian Assange’s internet link has been inten...       1   \n",
       "799                                   [Richard Belzer]       0   \n",
       "\n",
       "                                              keywords  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2                                                        \n",
       "3    Alan Rickman,Hilly Kristal,new rupert grint mo...   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "795  givebackfilms,give back films,video,random act...   \n",
       "796  donald trump, texas, electoral college, faithl...   \n",
       "797  acne, Skincare, beauty, Beauty pageant, Dermat...   \n",
       "798       dead man's switch, julian assange, wikileaks   \n",
       "799  TV Canada,richard belzer leaving law and order...   \n",
       "\n",
       "                                 spoilerPositions  \\\n",
       "0                          [[[2, 158], [2, 236]]]   \n",
       "1    [[[0, 197], [0, 212]], [[0, 215], [0, 328]]]   \n",
       "2                            [[[3, 58], [3, 61]]]   \n",
       "3      [[[-1, 0], [-1, 27]], [[0, 98], [0, 102]]]   \n",
       "4                           [[[1, 34], [1, 108]]]   \n",
       "..                                            ...   \n",
       "795                          [[[3, 0], [3, 150]]]   \n",
       "796                          [[[1, 45], [1, 63]]]   \n",
       "797   [[[2, 144], [2, 158]], [[6, 56], [6, 124]]]   \n",
       "798                         [[[11, 0], [11, 78]]]   \n",
       "799                           [[[0, 0], [0, 14]]]   \n",
       "\n",
       "                                         generated_que  \n",
       "0    What is the reason for the delay of the sequel...  \n",
       "1    What is the word that could determine the fate...  \n",
       "2     How much should you be tipping your hairdresser?  \n",
       "3    What is the name of the new movie in which \"Ha...  \n",
       "4                                  What happened next?  \n",
       "..                                                 ...  \n",
       "795  What happens when you leave a hotel cleaner a ...  \n",
       "796  What is the name of the Texas GOP elector who ...  \n",
       "797    What diet change cured the beauty queen's acne?  \n",
       "798               What is the meaning of the sentence?  \n",
       "799  What is the name of the original \"Law & Order:...  \n",
       "\n",
       "[800 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71989ea3-8c6b-4f44-a6c1-e0d669700419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the reason for the delay of the sequel to Five Nights at Freddy's?\n",
      "{'Reference Answer: ': 'some of the plot elements are so disturbing that they are making him feel sick', 'Predicted Answer: ': 'the sequel is due to a computer glitch that occurred during the development of the game.', 'BLEU Score: ': {'google_bleu': 0.06451612903225806}, 'Bert Score: ': {'precision': [0.8697110414505005], 'recall': [0.8611655235290527], 'f1': [0.8654171824455261], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.22321428571428575}\n",
      "-------- 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the word that could determine the fate of Arizona Sheriff Joe Arpaio?\n",
      "{'Reference Answer: ': '\"intentionally\" could transform a court case against Phoenix-area Sheriff Joe Arpaio from civil charges to a criminal prosecution', 'Predicted Answer: ': 'On May 31, Snow will determine the civil penalties and examine the motives of the three defendants', 'BLEU Score: ': {'google_bleu': 0.013513513513513514}, 'Bert Score: ': {'precision': [0.8624863624572754], 'recall': [0.8442448377609253], 'f1': [0.8532680869102478], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.02747252747252747}\n",
      "-------- 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " How much should you be tipping your hairdresser?\n",
      "{'Reference Answer: ': '20%', 'Predicted Answer: ': '20%', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999998807907104], 'recall': [0.9999998807907104], 'f1': [0.9999998807907104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the new movie in which \"Harry Potter\" alums are reuniting?\n",
      "{'Reference Answer: ': 'Alan Rickman & Rupert Grint CBGB', 'Predicted Answer: ': 'CBGB The Story of Alan Rickman The Story of Mr. Potter Themse', 'BLEU Score: ': {'google_bleu': 0.08695652173913043}, 'Bert Score: ': {'precision': [0.8170082569122314], 'recall': [0.8313930034637451], 'f1': [0.8241378664970398], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.22417153996101363}\n",
      "-------- 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What happened next?\n",
      "{'Reference Answer: ': 'a man who swallowed a 64GB microSD card and then pooped it into a strainer', 'Predicted Answer: ': \"he couldn't puke it back up, and therefore had to poop it\", 'BLEU Score: ': {'google_bleu': 0.037037037037037035}, 'Bert Score: ': {'precision': [0.8670387268066406], 'recall': [0.845383882522583], 'f1': [0.8560743927955627], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.18124507486209612}\n",
      "-------- 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the popular soda that scientists say could cure hangovers?\n",
      "{'Reference Answer: ': 'Sprite', 'Predicted Answer: ': 'Sprite', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999999403953552], 'recall': [0.9999999403953552], 'f1': [0.9999999403953552], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the anytime snack?\n",
      "{'Reference Answer: ': 'Smoky Paprika-Baked Garbanzo Beans', 'Predicted Answer: ': 'Smoky Paprika-Baked Garbanzo Beans', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9921875}\n",
      "-------- 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the stunning \"Harry Potter\" revelation about Professor McGonagall?\n",
      "{'Reference Answer: ': 'McGonagall was appointed as Dumbledore’s assistant in 1956, not as his replacement.', 'Predicted Answer: ': 'About 30 years ago, Obversa wrote that McGonagall was hired by Dumble', 'BLEU Score: ': {'google_bleu': 0.08}, 'Bert Score: ': {'precision': [0.8391275405883789], 'recall': [0.8633871078491211], 'f1': [0.8510844707489014], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1921470342522974}\n",
      "-------- 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the answer that J.J. Abrams has given about the post-credits scene in the new 'Star Wars'?\n",
      "{'Reference Answer: ': 'All the scenes are actually in the movie', 'Predicted Answer: ': 'some have wondered if this could be something new for the \"Star Wars\" series as well', 'BLEU Score: ': {'google_bleu': 0.015151515151515152}, 'Bert Score: ': {'precision': [0.8388441205024719], 'recall': [0.8542593717575073], 'f1': [0.8464815616607666], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.058823529411764705}\n",
      "-------- 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did Kristin Cavallari say about \"The Hills\"?\n",
      "{'Reference Answer: ': '\"I had fake relationships, fake fights. I don\\'t care anymore, I can tell you.', 'Predicted Answer: ': \"I had fake relationships, fake fights. I don't care anymore, I can tell\", 'BLEU Score: ': {'google_bleu': 0.8285714285714286}, 'Bert Score: ': {'precision': [0.9665760397911072], 'recall': [0.9550710916519165], 'f1': [0.960789144039154], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9799587975278516}\n",
      "-------- 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " How does this model prepare for lingerie shoots?\n",
      "{'Reference Answer: ': 'Elettra Wiedemann extra strength work, so weights, and quite a few planks for my core. My diet stayed pretty much the same, except I cut out sugar for the week of the shoot', 'Predicted Answer: ': 'Elettra Wiedemann intense preparation and posing in ultra-sexy ski', 'BLEU Score: ': {'google_bleu': 0.028169014084507043}, 'Bert Score: ': {'precision': [0.8967509865760803], 'recall': [0.8415740728378296], 'f1': [0.8682867884635925], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.21657250470809797}\n",
      "-------- 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " Who did Obama just dine with in Vietnam?\n",
      "{'Reference Answer: ': 'Anthony Bourdain', 'Predicted Answer: ': 'Anthony Bourdain', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the cause of death in the sentence?\n",
      "{'Reference Answer: ': \"he'd eaten a peanut butter sandwich and wasn't aware of her peanut allergy\", 'Predicted Answer: ': 'Myriam Ducre-Lemay, 20, died in 2012 after kissing her boyfriend', 'BLEU Score: ': {'google_bleu': 0.021739130434782608}, 'Bert Score: ': {'precision': [0.7836421728134155], 'recall': [0.8445446491241455], 'f1': [0.8129544258117676], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.04065040650406504}\n",
      "-------- 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the question that the former O.J. Simpson prosecutor hates being asked?\n",
      "{'Reference Answer: ': 'Marcia Clark Does she think Simpson really did it?', 'Predicted Answer: ': 'Marcia Clark \"It\\'s more than just a job, it\\'s something', 'BLEU Score: ': {'google_bleu': 0.07142857142857142}, 'Bert Score: ': {'precision': [0.8695942163467407], 'recall': [0.8930588960647583], 'f1': [0.881170392036438], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.18790849673202614}\n",
      "-------- 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the amazing home of the Hollywood legend on the market?\n",
      "{'Reference Answer: ': 'Mitzi Gaynor Beverly Hills, California', 'Predicted Answer: ': 'Mitzi Gaynor Beverly Hills, California home', 'BLEU Score: ': {'google_bleu': 0.8181818181818182}, 'Bert Score: ': {'precision': [0.9555147886276245], 'recall': [0.9854012727737427], 'f1': [0.9702279567718506], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8675523349436391}\n",
      "-------- 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are mosquito-control workers spraying in Miami?\n",
      "{'Reference Answer: ': 'Dibrom', 'Predicted Answer: ': 'naled', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8310245871543884], 'recall': [0.7743184566497803], 'f1': [0.8016699552536011], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the question being asked in the sentence?\n",
      "{'Reference Answer: ': 'They don’t fart', 'Predicted Answer: ': 'they don’t fart', 'BLEU Score: ': {'google_bleu': 0.5}, 'Bert Score: ': {'precision': [0.9931613206863403], 'recall': [0.9952150583267212], 'f1': [0.9941871166229248], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.996}\n",
      "-------- 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the most that the angry ex-boyfriend did?\n",
      "{'Reference Answer: ': 'kicked her and got into a fight with her current boyfriend', 'Predicted Answer: ': 'he burst into his ex-girlfriend’s delivery room, kicked her', 'BLEU Score: ': {'google_bleu': 0.10526315789473684}, 'Bert Score: ': {'precision': [0.8727032542228699], 'recall': [0.876312255859375], 'f1': [0.8745039701461792], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.12605042016806722}\n",
      "-------- 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the shocking move made by the local cops against the boy selling teddy bear to buy food?\n",
      "{'Reference Answer: ': 'Dunham picked the boy up and took him to a Subway to get something to eat. He then took him to the Franklin Police Department.', 'Predicted Answer: ': 'He told me he was trying to sell his stuffed animal to get money for food because', 'BLEU Score: ': {'google_bleu': 0.049019607843137254}, 'Bert Score: ': {'precision': [0.8534731864929199], 'recall': [0.8714210391044617], 'f1': [0.8623536825180054], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1111111111111111}\n",
      "-------- 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the secret that parents discovered in their adoptive daughter's family tree?\n",
      "{'Reference Answer: ': 'Not only does Aubrey have cerebral palsy, but she was neglected and abused by her biological mother.', 'Predicted Answer: ': 'Aubrey has cerebral palsy, but she was neglected and abused by her biological', 'BLEU Score: ': {'google_bleu': 0.6142857142857143}, 'Bert Score: ': {'precision': [0.9466792345046997], 'recall': [0.9301621913909912], 'f1': [0.9383480548858643], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8949194042032237}\n",
      "-------- 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the one morning work mistake you can't recover from?\n",
      "{'Reference Answer: ': 'starts later', 'Predicted Answer: ': 'start the day earlier', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8373060822486877], 'recall': [0.894322395324707], 'f1': [0.8648755550384521], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.13157894736842105}\n",
      "-------- 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is melatonin?\n",
      "{'Reference Answer: ': \"The bottom line: Unfortunately, there's not enough solid research out there on whether melatonin supplements are truly an effective and safe way to get to sleep.\", 'Predicted Answer: ': \"melatonin is a hormone released by the brain that helps regulate the body'\", 'BLEU Score: ': {'google_bleu': 0.00909090909090909}, 'Bert Score: ': {'precision': [0.8576525449752808], 'recall': [0.8424500226974487], 'f1': [0.8499833345413208], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06410256410256411}\n",
      "-------- 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What makes the author think that there will probably never be a \"Dawson's Creek\" reunion?\n",
      "{'Reference Answer: ': \"Kevin Williamson said he didn't want to write it\", 'Predicted Answer: ': 'James Van Der Beek The Capeside gang will likely never get back together', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8113104701042175], 'recall': [0.8518649339675903], 'f1': [0.8310933113098145], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the bombshell about the babies that the doctors drop?\n",
      "{'Reference Answer: ': 'Sophie and Riley were considered \"micro-preemies\" and suffered a slew of health issues, like chronic lung disease and holes in their hearts.', 'Predicted Answer: ': 'They were rushed to the hospital to stop her premature labor at just 25 weeks.', 'BLEU Score: ': {'google_bleu': 0.02040816326530612}, 'Bert Score: ': {'precision': [0.8638536930084229], 'recall': [0.8502219915390015], 'f1': [0.8569836020469666], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.058823529411764705}\n",
      "-------- 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the surprise in Apple iOS 9.3.2?\n",
      "{'Reference Answer: ': 'bricking iPad Pros', 'Predicted Answer: ': 'is bricking iPad Pros', 'BLEU Score: ': {'google_bleu': 0.6}, 'Bert Score: ': {'precision': [0.9282737374305725], 'recall': [0.9198660850524902], 'f1': [0.9240508675575256], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.754985754985755}\n",
      "-------- 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the main topic of the sentence?\n",
      "{'Reference Answer: ': 'Stace Nelson', 'Predicted Answer: ': 'Mike Rounds', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8328695297241211], 'recall': [0.7937979102134705], 'f1': [0.8128644227981567], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " How much do these Instagram models make?\n",
      "{'Reference Answer: ': 'Paige Hathaway – £3.8million Chantel Zales – £3.6 million Ana Cheri – £2.4 million Abigail Ratchford – £2.3 million Claudia Alende – £2.1 million', 'Predicted Answer: ': 'Paige Hathaway £3.8million', 'BLEU Score: ': {'google_bleu': 0.044444444444444446}, 'Bert Score: ': {'precision': [0.9449008107185364], 'recall': [0.8372739553451538], 'f1': [0.8878375291824341], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5010893246187365}\n",
      "-------- 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the conflict mentioned in the sentence?\n",
      "{'Reference Answer: ': 'Buss and Jackson announced that they were mutually ending their four-year engagement', 'Predicted Answer: ': \"Phil and Jeanie -- basketball's ultimate power couple -- call it quits\", 'BLEU Score: ': {'google_bleu': 0.023809523809523808}, 'Bert Score: ': {'precision': [0.8498992323875427], 'recall': [0.8566823601722717], 'f1': [0.853277325630188], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.03875968992248062}\n",
      "-------- 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What happened next after the tourist ignored the \"Please Don't Touch\" sign in the museum?\n",
      "{'Reference Answer: ': 'In the video, an abstract, wooden sculpture clock appeared not to be working, so a male tourist decided to take matters into his own hands, pulling on weights and levers for more than 30 seconds before the clock came flying off the wall and into pieces on the floor.', 'Predicted Answer: ': 'In the video, an abstract, wooden sculpture clock appeared not to be working, so a', 'BLEU Score: ': {'google_bleu': 0.3142857142857143}, 'Bert Score: ': {'precision': [0.9679954051971436], 'recall': [0.8841516971588135], 'f1': [0.9241758584976196], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6763688843164152}\n",
      "-------- 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the newest menu item at Taco Bell and what is the ridiculous ingredient?\n",
      "{'Reference Answer: ': 'reduced fat sour cream', 'Predicted Answer: ': 'reduced fat sour cream', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9921875}\n",
      "-------- 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the person mentioned in the sentence?\n",
      "{'Reference Answer: ': 'Brooks would eventually return to a role at News Corp, few expected her to land at Storyful', 'Predicted Answer: ': 'Rebekah Brooks, the former chief executive of News International, a subsidiary of', 'BLEU Score: ': {'google_bleu': 0.06060606060606061}, 'Bert Score: ': {'precision': [0.8108696937561035], 'recall': [0.833893358707428], 'f1': [0.8222204446792603], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1388888888888889}\n",
      "-------- 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the children's book illustrator who just got his own exhibition in Chicago?\n",
      "{'Reference Answer: ': 'Edward Gorey', 'Predicted Answer: ': 'Edward Gorey', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the fashion brand that lets models go un-Photoshopped and makeup-free?\n",
      "{'Reference Answer: ': 'Rag & Bone', 'Predicted Answer: ': 'Rag & Bone', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9814814814814815}\n",
      "-------- 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the Hollywood's biggest trend that Jennifer Lawrence debuted?\n",
      "{'Reference Answer: ': 'pixie cut', 'Predicted Answer: ': 'pixie cuts', 'BLEU Score: ': {'google_bleu': 0.3333333333333333}, 'Bert Score: ': {'precision': [0.9616676568984985], 'recall': [0.9616676568984985], 'f1': [0.9616676568984985], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the oven cleaning hacks that will have your appliance sparkling without ANY scrubbing?\n",
      "{'Reference Answer: ': 'homemade oven cleaner place the shelves in a resealable plastic bag, spray with oven cleaner, seal the bag, then leave to soak old toothbrush is an essential oven-cleaning tool glass scraper is ideal for removing tough stains remove greasy build-up on the hood of your oven with oil', 'Predicted Answer: ': '1. CREATE YOUR OWN CLEANER 2. USE A STARCH TIP 3.', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8353761434555054], 'recall': [0.7994390726089478], 'f1': [0.8170126080513], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.08474576271186442}\n",
      "-------- 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the \"this\" in the sentence referring to?\n",
      "{'Reference Answer: ': 'In February, when Rep. David Jolly introduced his quixotic plan to ban members of Congress from soliciting campaign contributions, the Florida Republican had only six co-sponsors.', 'Predicted Answer: ': 'No senator has come forward with similar legislation.', 'BLEU Score: ': {'google_bleu': 0.008771929824561403}, 'Bert Score: ': {'precision': [0.8763381242752075], 'recall': [0.8441141843795776], 'f1': [0.8599243760108948], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.045454545454545456}\n",
      "-------- 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did he rescue?\n",
      "{'Reference Answer: ': 'southern flying squirrel', 'Predicted Answer: ': 'southern flying squirrel', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9814814814814815}\n",
      "-------- 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the 29 most beautiful TV quotes of all time?\n",
      "{'Reference Answer: ': '1. \"You can\\'t live your life according to maybes.\" 2. \"I wish there was a way to know you’re in the good old days before you’ve actually left them.\" 3. \"And what exactly do you think fairy tales are? They are a reminder that our lives will get better if we just hold on to hope. Your happy ending may not be what you expect, but that is what will make it so special.\" 4. \"To exist is to survive unfair choices.\" 5. \"I don’t want normal, and easy, and simple. I want painful, difficult, devastating, life-changing, extraordinary love. Don’t you want that, too?\"', 'Predicted Answer: ': '1. \"You can\\'t live your life according to maybes.\" 2. \"I wish there', 'BLEU Score: ': {'google_bleu': 0.13011152416356878}, 'Bert Score: ': {'precision': [0.9345920085906982], 'recall': [0.8314789533615112], 'f1': [0.880025327205658], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.45784615384615385}\n",
      "-------- 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What happens just seconds later?\n",
      "{'Reference Answer: ': 'At this point, a large dog -- presumably Stella -- bounds into view, runs to one end of the fence and jumps right over it, almost without effort.', 'Predicted Answer: ': 'In the comments section of the video, the original poster explains why he thought the fence', 'BLEU Score: ': {'google_bleu': 0.04918032786885246}, 'Bert Score: ': {'precision': [0.8430463075637817], 'recall': [0.8250737190246582], 'f1': [0.8339632153511047], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.20108108108108108}\n",
      "-------- 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the price of the thing that someone just paid $168000 for?\n",
      "{'Reference Answer: ': \"Hope's antique cabinet\", 'Predicted Answer: ': \"Hope's antique cabinet\", 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999998807907104], 'recall': [0.9999998807907104], 'f1': [0.9999998807907104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9921875}\n",
      "-------- 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the 14 things that'll happen in 2017 according to \"The Simpsons\"?\n",
      "{'Reference Answer: ': '1. Some alt-right guy will invent the make-up gun. 2. There will be a referendum on whether or not to deport illegal immigrants. 3. Greedy, corrupt energy firms will cause an environmental catastrophe, and a dome will be built over the contaminated site. 4. The chandelier in Elton John’s private jet will malfunction. 5. It will be made illegal to teach evolution in schools.', 'Predicted Answer: ': '1. Some alt-right guy will invent the make-up gun 2. There will be ', 'BLEU Score: ': {'google_bleu': 0.1610738255033557}, 'Bert Score: ': {'precision': [0.9479125738143921], 'recall': [0.8527683019638062], 'f1': [0.8978267908096313], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5653625456442358}\n",
      "-------- 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the main reason for the author's poor performance in sports during high school?\n",
      "{'Reference Answer: ': 'Some people are just better at sports than others', 'Predicted Answer: ': 'I was really bad at sports in high school', 'BLEU Score: ': {'google_bleu': 0.1}, 'Bert Score: ': {'precision': [0.889342188835144], 'recall': [0.8691595196723938], 'f1': [0.879135012626648], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.20833333333333331}\n",
      "-------- 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the official departure date of Jon Stewart from The Daily Show?\n",
      "{'Reference Answer: ': 'August 6th', 'Predicted Answer: ': 'August 6', 'BLEU Score: ': {'google_bleu': 0.3333333333333333}, 'Bert Score: ': {'precision': [0.9240704774856567], 'recall': [0.8855890035629272], 'f1': [0.9044206142425537], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.25}\n",
      "-------- 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the size of Justin Bieber's penis?\n",
      "{'Reference Answer: ': 'perfectly average', 'Predicted Answer: ': '7.25 inches', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8642019629478455], 'recall': [0.8486595153808594], 'f1': [0.8563601970672607], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the word that should never follow \"I love you\"?\n",
      "{'Reference Answer: ': '\"but\"', 'Predicted Answer: ': 'I would love you', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8161446452140808], 'recall': [0.8008577823638916], 'f1': [0.8084288835525513], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the time for getting up close and personal with a rocket launch?\n",
      "{'Reference Answer: ': 'On Tuesday morning, NASA will broadcast its first-ever rocket launch livestream in 360-degree video', 'Predicted Answer: ': 'On Tuesday morning, NASA will broadcast its first-ever rocket launch livestream in 360-degree', 'BLEU Score: ': {'google_bleu': 0.9354838709677419}, 'Bert Score: ': {'precision': [0.9959357976913452], 'recall': [0.9891334772109985], 'f1': [0.9925230145454407], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9927268779852366}\n",
      "-------- 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the meaning of the sentence?\n",
      "{'Reference Answer: ': 'Vince Carter Paul Pierce Dirk Nowitzki', 'Predicted Answer: ': 'Carter, Nowitzki and Paul Pierce', 'BLEU Score: ': {'google_bleu': 0.2777777777777778}, 'Bert Score: ': {'precision': [0.9078690409660339], 'recall': [0.9063087105751038], 'f1': [0.9070882201194763], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5260416666666666}\n",
      "-------- 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the problem that the sentence suggests the person solved?\n",
      "{'Reference Answer: ': 'Baking soda bee stings', 'Predicted Answer: ': '1. Mouthwash for your feet 2. Black tea for sunburns 3. Hot tap water for', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8267672657966614], 'recall': [0.8004380464553833], 'f1': [0.8133895993232727], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the newspaper?\n",
      "{'Reference Answer: ': 'The Arizona Republic', 'Predicted Answer: ': 'Arizona Republic', 'BLEU Score: ': {'google_bleu': 0.5}, 'Bert Score: ': {'precision': [0.935716986656189], 'recall': [0.8778082132339478], 'f1': [0.9058380722999573], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8928571428571429}\n",
      "-------- 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the meaning of the sentence?\n",
      "{'Reference Answer: ': 'I don’t think we should be starting to panic', 'Predicted Answer: ': 'In the traditional view of cancer, mutations strike a cell. However they arise, they', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8374897241592407], 'recall': [0.8481332063674927], 'f1': [0.8427778482437134], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the belief about the Syria conflict?\n",
      "{'Reference Answer: ': 'apocalyptic omen', 'Predicted Answer: ': 'Revelation', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.9062913656234741], 'recall': [0.7840139865875244], 'f1': [0.8407298922538757], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What happened to the speaker's honeymoon?\n",
      "{'Reference Answer: ': 'Rudner and her husband rented ATVs. After hitting a speed bump and falling off of the vehicle, her husband shattered his shoulder and Rudner rotated her hip', 'Predicted Answer: ': 'After hitting a speed bump and falling off the vehicle, her husband shattered his', 'BLEU Score: ': {'google_bleu': 0.43636363636363634}, 'Bert Score: ': {'precision': [0.9409735798835754], 'recall': [0.8898792266845703], 'f1': [0.914713442325592], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8853658536585366}\n",
      "-------- 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the drug that could add five years to a dog's life?\n",
      "{'Reference Answer: ': 'rapamycin', 'Predicted Answer: ': 'rapamycin', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0000001192092896], 'recall': [1.0000001192092896], 'f1': [1.0000001192092896], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the Catholic university that has dropped abortion coverage?\n",
      "{'Reference Answer: ': 'Santa Clara University', 'Predicted Answer: ': 'Santa Clara University', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999999403953552], 'recall': [0.9999999403953552], 'f1': [0.9999999403953552], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9814814814814815}\n",
      "-------- 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the president of the college trying to convey to the students by saying \"This is not a day care. This is a university!\"\n",
      "{'Reference Answer: ': 'Oklahoma Wesleyan University', 'Predicted Answer: ': 'this is a university', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8642750978469849], 'recall': [0.8126308917999268], 'f1': [0.8376577496528625], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.12820512820512822}\n",
      "-------- 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the bedroom blues?\n",
      "{'Reference Answer: ': 'The sadness some men feel at this point may be due to the contrast between the joy of arousal and feeling like a superhero and the sensation of the feel-good hormones wearing off.', 'Predicted Answer: ': \"'Post-coital dysphoria' for hours after having sex\", 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8612263798713684], 'recall': [0.8478219509124756], 'f1': [0.8544716238975525], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the Amazon-Hachette war?\n",
      "{'Reference Answer: ': 'Edan Lepucki', 'Predicted Answer: ': 'Edan Lepucki', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the occupation of the NFL player mentioned in the sentence?\n",
      "{'Reference Answer: ': 'Tim Masthay', 'Predicted Answer: ': 'Green Bay Packers punter Tim Masthay', 'BLEU Score: ': {'google_bleu': 0.16666666666666666}, 'Bert Score: ': {'precision': [0.83724045753479], 'recall': [0.9162061214447021], 'f1': [0.8749452233314514], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.33482142857142855}\n",
      "-------- 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the main point being made in this sentence?\n",
      "{'Reference Answer: ': 'But psychedelics may not be as dangerous and addictive as our society thinks.', 'Predicted Answer: ': 'Many of the negative perceptions we have of psychedelics can be traced back', 'BLEU Score: ': {'google_bleu': 0.04}, 'Bert Score: ': {'precision': [0.8779482841491699], 'recall': [0.8828686475753784], 'f1': [0.8804015517234802], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.07633587786259544}\n",
      "-------- 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the weight of the orange object that can be seen in New York this week?\n",
      "{'Reference Answer: ': \"World's Largest Pumpkin\", 'Predicted Answer: ': '2,032 pounds', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.7446298599243164], 'recall': [0.7806365489959717], 'f1': [0.7622082233428955], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did Paris Hilton drop on two teeny-tiny dogs?\n",
      "{'Reference Answer: ': '$25K', 'Predicted Answer: ': '$25K', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did the guy do wrong?\n",
      "{'Reference Answer: ': 'If you find yourself so moved to store ice cream in your back pocket in Alabama, you’ll pay the price, and we don’t just mean a cold rear end.', 'Predicted Answer: ': '1. Feeding the homeless. 2. Never returning a video. 3. Giving a we', 'BLEU Score: ': {'google_bleu': 0.03278688524590164}, 'Bert Score: ': {'precision': [0.8527596592903137], 'recall': [0.8173755407333374], 'f1': [0.8346927165985107], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1262626262626263}\n",
      "-------- 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the method to completely eliminate stress in just three minutes?\n",
      "{'Reference Answer: ': 'close your eyes or simply stare at a fixed point Next, turn all focus to pulling in your breath Then, simply sigh Then start counting the breath in and out through the nose repeat this eight times', 'Predicted Answer: ': 'You need incense, candles or to be sat legs crossed on the floor ', 'BLEU Score: ': {'google_bleu': 0.02666666666666667}, 'Bert Score: ': {'precision': [0.8290976881980896], 'recall': [0.7992941737174988], 'f1': [0.813923180103302], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.1212121212121212}\n",
      "-------- 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the purpose of \"Sex Week\" at the university?\n",
      "{'Reference Answer: ': 'University of Tennessee', 'Predicted Answer: ': 'Tennessee', 'BLEU Score: ': {'google_bleu': 0.16666666666666666}, 'Bert Score: ': {'precision': [0.8879318833351135], 'recall': [0.7871273756027222], 'f1': [0.8344963788986206], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.4166666666666667}\n",
      "-------- 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did the ex-basketball player do that made people angry?\n",
      "{'Reference Answer: ': 'Almario alleged physical abuse and uploading their sex video online', 'Predicted Answer: ': 'Alvin Japhet Almario he started abusing her', 'BLEU Score: ': {'google_bleu': 0.029411764705882353}, 'Bert Score: ': {'precision': [0.8380369544029236], 'recall': [0.8536390662193298], 'f1': [0.8457660675048828], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.136986301369863}\n",
      "-------- 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the most annoying thing on the entire planet?\n",
      "{'Reference Answer: ': 'Crazy Frog', 'Predicted Answer: ': 'Crazy Frog', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999998807907104], 'recall': [0.9999998807907104], 'f1': [0.9999998807907104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the main topic of the sentence?\n",
      "{'Reference Answer: ': '\"Although astrologers seek to explain the natural world, they don\\'t usually attempt to critically evaluate whether those explanations are valid — and this is a key part of science.\"', 'Predicted Answer: ': '\"There is no scientific basis for astrology. It’s a holistic approach.\"', 'BLEU Score: ': {'google_bleu': 0.047619047619047616}, 'Bert Score: ': {'precision': [0.9092420339584351], 'recall': [0.8735024929046631], 'f1': [0.8910139799118042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.22801544860368395}\n",
      "-------- 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the first thing guys notice about women?\n",
      "{'Reference Answer: ': 'face', 'Predicted Answer: ': 'your butt', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8574358224868774], 'recall': [0.9195597767829895], 'f1': [0.8874118328094482], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the latest Hollywood baby?\n",
      "{'Reference Answer: ': 'Rachel Zoe Gives Birth To Her Second Baby Boy!', 'Predicted Answer: ': 'Rachel Zoe', 'BLEU Score: ': {'google_bleu': 0.08823529411764706}, 'Bert Score: ': {'precision': [0.8984192609786987], 'recall': [0.788816511631012], 'f1': [0.8400579690933228], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6696428571428572}\n",
      "-------- 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the company that is crushing America's biggest clothing stores?\n",
      "{'Reference Answer: ': 'Amazon', 'Predicted Answer: ': 'Amazon', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the shower habits that you need to stop doing immediately?\n",
      "{'Reference Answer: ': '1. Washing Your Face 2. Not Washing Your Feet 3. Not Washing or Replacing Your Loofah Regularly 4. Using a Soap Dish 5. Using Scented Soaps', 'Predicted Answer: ': '1. Stop using the shower as a toilet 2. Wash your hair 3. Leave your shower clean and', 'BLEU Score: ': {'google_bleu': 0.0847457627118644}, 'Bert Score: ': {'precision': [0.8909581303596497], 'recall': [0.8618637919425964], 'f1': [0.8761695027351379], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.25}\n",
      "-------- 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the disease mentioned in the sentence?\n",
      "{'Reference Answer: ': 'kuru', 'Predicted Answer: ': 'Papillomavirus', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.6908575296401978], 'recall': [0.8041756749153137], 'f1': [0.7432220578193665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the dangerous plant that can kill children?\n",
      "{'Reference Answer: ': 'Dieffenbachia', 'Predicted Answer: ': 'Dieffenbachia', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " Are left-handed people really more creative than right-handed people?\n",
      "{'Reference Answer: ': 'The answer to that is a definitive ... maybe.', 'Predicted Answer: ': 'They’re more likely to be creative', 'BLEU Score: ': {'google_bleu': 0.023809523809523808}, 'Bert Score: ': {'precision': [0.8351598978042603], 'recall': [0.7975113391876221], 'f1': [0.815901517868042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.12195121951219512}\n",
      "-------- 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the name of the \"unknown substance\" that sent 7 Planned Parenthood staffers to the hospital?\n",
      "{'Reference Answer: ': 'baby food', 'Predicted Answer: ': 'baby food', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999998807907104], 'recall': [0.9999998807907104], 'f1': [0.9999998807907104], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9375}\n",
      "-------- 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What has Michael Douglass' son Cameron tattooed on his abs?\n",
      "{'Reference Answer: ': 'Michael and Kirk', 'Predicted Answer: ': 'Michael and Kirk Douglass', 'BLEU Score: ': {'google_bleu': 0.6}, 'Bert Score: ': {'precision': [0.8846010565757751], 'recall': [0.9553971886634827], 'f1': [0.9186370968818665], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.754985754985755}\n",
      "-------- 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the cancer-causing ingredient lurking in your beauty products?\n",
      "{'Reference Answer: ': '1,4-dioxane', 'Predicted Answer: ': '1,4-dioxane', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0], 'recall': [1.0], 'f1': [1.0], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the surprising thing that may be making you crave junk food?\n",
      "{'Reference Answer: ': 'gut bacteria', 'Predicted Answer: ': 'yogurt', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.9043344855308533], 'recall': [0.8356538414955139], 'f1': [0.8686386942863464], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What does it feel like to die?\n",
      "{'Reference Answer: ': 'from the last two weeks until the last breath, somewhere in that interval, people become too sick, or too drowsy, or too unconscious, to tell us what they’re experiencing Pre-death dreams were frequently so intense that the dream carried into wakefulness. First hunger and then thirst are lost. Speech is lost next, followed by vision. The last senses to go are usually hearing and touch. There are some kinds of conditions where pain is inevitable We generally believe that if your brain is really in a comatose kind of situation, or you’re not really responsive, that your perception—how you feel about things—may also be significantly decreased,', 'Predicted Answer: ': '\"I don’t know if there’s going to be a hospice nurse next', 'BLEU Score: ': {'google_bleu': 0.010638297872340425}, 'Bert Score: ': {'precision': [0.8515479564666748], 'recall': [0.8001362681388855], 'f1': [0.8250419497489929], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.16304347826086957}\n",
      "-------- 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What state is NOT excited about legal weed?\n",
      "{'Reference Answer: ': 'Wyoming', 'Predicted Answer: ': 'Wyoming', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0000001192092896], 'recall': [1.0000001192092896], 'f1': [1.0000001192092896], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the company's policy on bringing pets to work?\n",
      "{'Reference Answer: ': 'Nvidia', 'Predicted Answer: ': 'Nvidia', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [1.0000001192092896], 'recall': [1.0000001192092896], 'f1': [1.0000001192092896], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the reason behind the sudden absence of certain letters in big brand names?\n",
      "{'Reference Answer: ': \"it's all part of a massive effort to encourage people around the globe to donate blood\", 'Predicted Answer: ': \"A's, B's and O's\", 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.782738208770752], 'recall': [0.8020256757736206], 'f1': [0.7922645807266235], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.11235955056179776}\n",
      "-------- 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the answer to the question posed in the sentence?\n",
      "{'Reference Answer: ': 'Republican voters would enthusiastically welcome a black candidate, a Donell Trump — so long as he, too, championed nationalist, politically incorrect, anti-immigrant populism.', 'Predicted Answer: ': 'If so, the answer is yes', 'BLEU Score: ': {'google_bleu': 0.01818181818181818}, 'Bert Score: ': {'precision': [0.8331021070480347], 'recall': [0.8217373490333557], 'f1': [0.8273806571960449], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.10869565217391305}\n",
      "-------- 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What do Americans drink every day?\n",
      "{'Reference Answer: ': '2.1 coffee drinks', 'Predicted Answer: ': '2.1 coffee drinks per day', 'BLEU Score: ': {'google_bleu': 0.42857142857142855}, 'Bert Score: ': {'precision': [0.9058703184127808], 'recall': [0.9294469356536865], 'f1': [0.9175072312355042], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.6134259259259259}\n",
      "-------- 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the reason behind this model suing for $1.5 billion?\n",
      "{'Reference Answer: ': 'Yuliana Avalos Match.com’s parent company, IAC (InterActiveCorp)', 'Predicted Answer: ': 'Yuliana Avalos Match.com allegedly allowed more than 200 fake profiles to post', 'BLEU Score: ': {'google_bleu': 0.2}, 'Bert Score: ': {'precision': [0.89150470495224], 'recall': [0.8703263998031616], 'f1': [0.880788266658783], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.24537037037037038}\n",
      "-------- 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the claim made in the sentence?\n",
      "{'Reference Answer: ': 'you’d still have a hard time arguing they were even the worst band on this stage', 'Predicted Answer: ': 'It feels hypocritical to use the old ‘Can X number of people really be wrong?', 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8322625160217285], 'recall': [0.8475118279457092], 'f1': [0.8398179411888123], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.05847953216374269}\n",
      "-------- 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What was the strategy that Obama's female staffers came up with to ensure their voices were heard?\n",
      "{'Reference Answer: ': 'Female staffers adopted a meeting strategy they called \"amplification\": When a woman made a key point, other women would repeat it, giving credit to its author.', 'Predicted Answer: ': 'When Obama first took office, the White House was the place where women could voice their opinions', 'BLEU Score: ': {'google_bleu': 0.02459016393442623}, 'Bert Score: ': {'precision': [0.8604342937469482], 'recall': [0.8584007024765015], 'f1': [0.8594163060188293], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.10309278350515463}\n",
      "-------- 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the ways in which Beats Electronics tricks consumers into thinking that its products are premium?\n",
      "{'Reference Answer: ': 'In these headphones, 30% of the weight comes from four tiny metal parts that are there for the sole purpose of adding weight', 'Predicted Answer: ': 'The company cuts corners everywhere it can; excluding hard drives and plastics.', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8623230457305908], 'recall': [0.8412480354309082], 'f1': [0.8516551852226257], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.033112582781456956}\n",
      "-------- 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the clever trick that will instantly clear your lawn of unwanted leaves?\n",
      "{'Reference Answer: ': 'giant piece of cardboard', 'Predicted Answer: ': 'cardboard', 'BLEU Score: ': {'google_bleu': 0.1}, 'Bert Score: ': {'precision': [0.8743352293968201], 'recall': [0.7852595448493958], 'f1': [0.8274068832397461], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.3846153846153847}\n",
      "-------- 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the theory about why Donald Trump keeps winning?\n",
      "{'Reference Answer: ': 'Solomon’s recent research shows that people who are thinking about death are more likely to say they support him', 'Predicted Answer: ': 'people who are thinking about death are more likely to say they support him', 'BLEU Score: ': {'google_bleu': 0.7142857142857143}, 'Bert Score: ': {'precision': [0.9682577848434448], 'recall': [0.9354591369628906], 'f1': [0.9515759348869324], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.952207413577676}\n",
      "-------- 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are some of the curious cases and unsolved mysteries that perplexed us in 2016?\n",
      "{'Reference Answer: ': 'Mark and Jacoba Tromp and their adult children Ella, Riana and Mitchell left their home in Silvan, east of Melbourne, taking cash but leaving behind bank cards and mobile phones. Hundreds of kangaroos were found dead in far west New South Wales this year from what was described as a \"mystery disease\". When a magnitude 7.8 earthquake struck near Christchurch in November, videos emerged that appeared to show the New Zealand sky lighting up in blue and green. This year it was reported that doctors were at a loss to explain the mysterious illness making a four-year-old Bangladeshi boy look like an old man. The FBI announced this year that one of America\\'s most baffling crimes — that of hijacker Dan \"DB Cooper\" who jumped out of a plane with a parachute and ransom money 45 years ago — looks set to remain an enigma.', 'Predicted Answer: ': 'One day later he left the family trip at Bathurst, describing his parents as scared', 'BLEU Score: ': {'google_bleu': 0.007987220447284345}, 'Bert Score: ': {'precision': [0.849045991897583], 'recall': [0.7912085652351379], 'f1': [0.8191075921058655], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.11551155115511552}\n",
      "-------- 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What are the worst jobs that ex-cons remember after being released from prison?\n",
      "{'Reference Answer: ': 'working on a cattle ranch as a utility farmer, picking up trash at the city dump in 100-plus degree weather telemarketing place', 'Predicted Answer: ': '1. Bank Manager 2. Accountant 3. Child Protective Services 4. Bank Manager 5. Resigning Officer', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8274022340774536], 'recall': [0.8054890632629395], 'f1': [0.8162986040115356], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the issue with the internet ruling that Verizon and AT&T don't like?\n",
      "{'Reference Answer: ': 'net neutrality', 'Predicted Answer: ': 'book', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.8657258749008179], 'recall': [0.8069858551025391], 'f1': [0.8353245258331299], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      "-------- 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did this teen do instead of giving a graduation speech?\n",
      "{'Reference Answer: ': 'sang his very own special rendition of Lukas Graham’s hit song \"7 Years.\"', 'Predicted Answer: ': 'JP Wallace got on the radio and started talking about how he felt about graduating.', 'BLEU Score: ': {'google_bleu': 0.017241379310344827}, 'Bert Score: ': {'precision': [0.8554275631904602], 'recall': [0.8453659415245056], 'f1': [0.8503669500350952], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0617283950617284}\n",
      "-------- 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the title of the next Star Wars movie?\n",
      "{'Reference Answer: ': 'Fall of the Resistance.', 'Predicted Answer: ': 'Fall of the Resistance', 'BLEU Score: ': {'google_bleu': 0.7142857142857143}, 'Bert Score: ': {'precision': [0.980004072189331], 'recall': [0.983994722366333], 'f1': [0.9819953441619873], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.9679878048780488}\n",
      "-------- 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What did we figure out when the moon formed?\n",
      "{'Reference Answer: ': '4.47 billion years ago', 'Predicted Answer: ': 'about 4.47 billion years ago', 'BLEU Score: ': {'google_bleu': 0.7142857142857143}, 'Bert Score: ': {'precision': [0.958686351776123], 'recall': [0.9711072444915771], 'f1': [0.9648568034172058], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8099489795918368}\n",
      "-------- 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What country recently decriminalized marijuana?\n",
      "{'Reference Answer: ': 'Switzerland', 'Predicted Answer: ': 'Switzerland', 'BLEU Score: ': {'google_bleu': 1.0}, 'Bert Score: ': {'precision': [0.9999999403953552], 'recall': [0.9999999403953552], 'f1': [0.9999999403953552], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.5}\n",
      "-------- 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the disturbing reason?\n",
      "{'Reference Answer: ': 'They are soaked in a bath of chlorine', 'Predicted Answer: ': 'They aren’t small carrots. No, baby carrots are big carrots that', 'BLEU Score: ': {'google_bleu': 0.043478260869565216}, 'Bert Score: ': {'precision': [0.8415586352348328], 'recall': [0.8600798845291138], 'f1': [0.8507184982299805], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.06993006993006992}\n",
      "-------- 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the iPhone 5C number that Apple doesn't want you to know?\n",
      "{'Reference Answer: ': 'preorder figure was 2 million', 'Predicted Answer: ': '2 million', 'BLEU Score: ': {'google_bleu': 0.21428571428571427}, 'Bert Score: ': {'precision': [0.8882178664207458], 'recall': [0.8407328128814697], 'f1': [0.8638232350349426], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.8152173913043478}\n",
      "-------- 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \n",
      " What is the reason the mother glued pennies to her daughter's shoes?\n",
      "{'Reference Answer: ': 'make-shift tap shoes', 'Predicted Answer: ': 'they were too expensive', 'BLEU Score: ': {'google_bleu': 0.0}, 'Bert Score: ': {'precision': [0.84417724609375], 'recall': [0.8330268263816833], 'f1': [0.838564932346344], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.41.0.dev0)'}, 'Meteor Score: ': 0.0}\n",
      " All 0.9004877907037735\n",
      " Phrase 0.9323202384279129\n",
      " Passage 0.8705274760723114\n",
      " Multi 0.8753575619898344\n"
     ]
    }
   ],
   "source": [
    "_all = {}\n",
    "arr = [{} for i in range(3)]\n",
    "bleu = 0\n",
    "meteor_int = 0\n",
    "bert = 0\n",
    "count = 0\n",
    "\n",
    "for i in range(100):\n",
    "    print('--------', i)\n",
    "    question = validation_dataset.iloc[i]['generated_que']\n",
    "    context = validation_dataset.iloc[i]['article']\n",
    "    answer = ' '.join(validation_dataset.iloc[i]['spoiler'])\n",
    "    label = validation_dataset.iloc[i]['labels']\n",
    "\n",
    "    # print(validation_dataset.iloc[i]['labels'])\n",
    "    ans = predict_answer(context, question, label, answer)\n",
    "    _all['bleu'] = _all.get('bleu', 0) + ans[\"BLEU Score: \"]['google_bleu']\n",
    "    _all['bert'] = _all.get('bert', 0) + ans['Bert Score: ']['precision'][0]\n",
    "    _all['meteor'] = _all.get('meteor', 0) + ans['Meteor Score: ']\n",
    "\n",
    "\n",
    "    type = validation_dataset.iloc[i]['labels']\n",
    "    arr[type]['bleu'] = arr[type].get('bleu',0) + ans[\"BLEU Score: \"]['google_bleu']\n",
    "    arr[type]['bert'] = arr[type].get('bert',0) + ans[\"Bert Score: \"]['precision'][0]\n",
    "    arr[type]['meteor'] = arr[type].get('meteor',0) + ans[\"Meteor Score: \"]\n",
    "    arr[type]['count'] = arr[type].get('count',0) + 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    print(ans)\n",
    "    # if validation_dataset.iloc[i]['labels'] == 2:\n",
    "    #     continue\n",
    "    count += 1\n",
    "    bleu += ans[\"BLEU Score: \"]['google_bleu']\n",
    "    bert += ans[\"Bert Score: \"]['precision'][0]\n",
    "    meteor_int += ans[\"Meteor Score: \"]\n",
    "    \n",
    "    \n",
    "\n",
    "print(\" All \" + str(_all['bert']/100))\n",
    "print(\" Phrase \" + str(arr[0]['bert']/arr[0]['count']))\n",
    "print(\" Passage \" + str(arr[1]['bert']/arr[1]['count']))\n",
    "print(\" Multi \" + str(arr[2]['bert']/arr[2]['count']))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc7c6014-ac48-4c9f-a70a-fe27e145a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3320358861768656\n",
      "0.9004877907037735\n",
      "0.39203029255122696\n"
     ]
    }
   ],
   "source": [
    "print(bleu/count)\n",
    "print(bert/count)\n",
    "print(meteor_int/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77e5534-76f5-4c70-ac64-bc8927506571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------       bleu-score           bert-score             meteor-score\n",
      " All       0.3320358861768656    0.9004877907037735   0.39203029255122696\n",
      " Phrase    0.5610942249240123    0.9323202384279129    0.5462192181787294\n",
      " Passage   0.14187682187373252     0.8705274760723114   0.2581797331172759\n",
      " Multi     0.10570253171321424    0.8753575619898344   0.25013763551237\n"
     ]
    }
   ],
   "source": [
    "print(\"----------       bleu-score           bert-score             meteor-score\")\n",
    "print(\" All      \", _all['bleu']/100, \"  \", _all['bert']/100, \" \", _all['meteor']/100)\n",
    "print(\" Phrase   \", arr[0]['bleu']/arr[0]['count'], \"  \", arr[0]['bert']/arr[0]['count'],  \"  \", arr[0]['meteor']/arr[0]['count'])\n",
    "print(\" Passage  \", arr[1]['bleu']/arr[1]['count'], \"   \", arr[1]['bert']/arr[1]['count'], \" \", arr[1]['meteor']/arr[1]['count'])\n",
    "print(\" Multi    \", arr[2]['bleu']/arr[2]['count'], \"  \", arr[2]['bert']/arr[2]['count'], \" \", arr[2]['meteor']/arr[2]['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef912be-61fb-43e2-b5ee-d79caaca7479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
